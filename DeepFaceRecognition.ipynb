{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T18:09:22.225655Z",
     "start_time": "2025-01-14T18:09:22.149015Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from tabnanny import verbose\n",
    "\n",
    "def rename_files_and_folders(root_path):\n",
    "    for dirpath, dirnames, filenames in os.walk(root_path):\n",
    "        # Renommer les dossiers\n",
    "        for dirname in dirnames:\n",
    "            new_dirname = dirname.encode(\"ascii\", \"ignore\").decode(\"ascii\").replace(\" \", \"_\")\n",
    "            os.rename(os.path.join(dirpath, dirname), os.path.join(dirpath, new_dirname))\n",
    "\n",
    "        # Renommer les fichiers\n",
    "        for filename in filenames:\n",
    "            new_filename = filename.encode(\"ascii\", \"ignore\").decode(\"ascii\").replace(\" \", \"_\")\n",
    "            os.rename(os.path.join(dirpath, filename), os.path.join(dirpath, new_filename))\n",
    "\n",
    "dataset_path = \"dataset(test)\"\n",
    "rename_files_and_folders(dataset_path)\n",
    "print(\"Renommage terminé.\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renommage terminé.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T18:39:25.650640Z",
     "start_time": "2025-01-14T18:37:23.249858Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk, messagebox, filedialog\n",
    "from deepface import DeepFace\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import threading\n",
    "from datetime import datetime\n",
    "from ultralytics import YOLO\n",
    "import logging\n",
    "import sys\n",
    "import json\n",
    "import hashlib\n",
    "\n",
    "class LoginWindow:\n",
    "    def __init__(self):\n",
    "        self.root = tk.Tk()\n",
    "        self.root.title(\"Connexion\")\n",
    "        self.root.geometry(\"300x250\")  # Augmenté la hauteur pour le nouveau menu\n",
    "\n",
    "        # Variables\n",
    "        self.password_var = tk.StringVar()\n",
    "        self.action_var = tk.StringVar(value=\"Entrée\")\n",
    "        self.salle_var = tk.StringVar(value=\"100\")  # Valeur par défaut pour la salle\n",
    "\n",
    "        self.create_widgets()\n",
    "\n",
    "    def create_widgets(self):\n",
    "        main_frame = ttk.Frame(self.root, padding=\"20\")\n",
    "        main_frame.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))\n",
    "\n",
    "        # Password field\n",
    "        ttk.Label(main_frame, text=\"Mot de passe:\").grid(row=0, column=0, pady=10)\n",
    "        password_entry = ttk.Entry(main_frame, textvariable=self.password_var, show=\"*\")\n",
    "        password_entry.grid(row=0, column=1, pady=10)\n",
    "\n",
    "        # Action choice (Entrée/Sortie)\n",
    "        ttk.Label(main_frame, text=\"Action:\").grid(row=1, column=0, pady=10)\n",
    "        action_frame = ttk.Frame(main_frame)\n",
    "        action_frame.grid(row=1, column=1, pady=10)\n",
    "\n",
    "        ttk.Radiobutton(action_frame, text=\"Entrée\", variable=self.action_var,\n",
    "                       value=\"Entrée\").pack(side=tk.LEFT, padx=5)\n",
    "        ttk.Radiobutton(action_frame, text=\"Sortie\", variable=self.action_var,\n",
    "                       value=\"Sortie\").pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        # Salle selection\n",
    "        ttk.Label(main_frame, text=\"Numéro de salle:\").grid(row=2, column=0, pady=10)\n",
    "        salles = [str(num) for num in range(100, 111)]  # Crée une liste de \"100\" à \"110\"\n",
    "        salle_combobox = ttk.Combobox(main_frame, textvariable=self.salle_var,\n",
    "                                     values=salles, state=\"readonly\", width=17)\n",
    "        salle_combobox.grid(row=2, column=1, pady=10)\n",
    "\n",
    "        # Login button\n",
    "        ttk.Button(main_frame, text=\"Connexion\",\n",
    "                  command=self.verify_password).grid(row=3, column=0,\n",
    "                                                   columnspan=2, pady=20)\n",
    "\n",
    "        # Center the frame\n",
    "        self.root.grid_rowconfigure(0, weight=1)\n",
    "        self.root.grid_columnconfigure(0, weight=1)\n",
    "\n",
    "    def verify_password(self):\n",
    "        entered_password = self.password_var.get()\n",
    "        action = self.action_var.get()\n",
    "        salle = self.salle_var.get()\n",
    "\n",
    "        # Hash the entered password\n",
    "        hashed_password = hashlib.sha256(entered_password.encode()).hexdigest()\n",
    "\n",
    "        try:\n",
    "            # Load the stored password\n",
    "            with open(\"password_config.json\", \"r\") as f:\n",
    "                config = json.load(f)\n",
    "                stored_password = config.get(\"password\")\n",
    "\n",
    "            if hashed_password == stored_password:\n",
    "                self.root.destroy()  # Close login window\n",
    "                # Start main application\n",
    "                root = tk.Tk()\n",
    "                app = FaceObjectRecognitionApp(root, action, salle)\n",
    "                root.mainloop()\n",
    "            else:\n",
    "                messagebox.showerror(\"Erreur\", \"Mot de passe incorrect\")\n",
    "                self.password_var.set(\"\")  # Clear password field\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            messagebox.showerror(\"Erreur\", \"Fichier de configuration non trouvé\")\n",
    "\n",
    "    def run(self):\n",
    "        self.root.mainloop()\n",
    "\n",
    "class FaceObjectRecognitionApp:\n",
    "    def __init__(self, root, action=\"Entrée\", salle=\"100\"):\n",
    "        self.root = root\n",
    "        self.action = action  # Stocke l'action (Entrée/Sortie)\n",
    "        self.salle = salle    # Stocke le numéro de salle\n",
    "        self.root.title(f\"Système de Reconnaissance - {action} - Salle {salle}\")\n",
    "        self.root.geometry(\"600x500\")\n",
    "\n",
    "        # Variables\n",
    "        self.is_recognition_running = False\n",
    "        self.training_in_progress = False\n",
    "        self.model_yolo = None\n",
    "        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "        # Objets surveillés\n",
    "        self.OBJETS_SURVEILLES = {\n",
    "            'Sunglasses': 505,\n",
    "            'Hat': 243,\n",
    "            'Shorts': 456,\n",
    "            'Skirt': 463,\n",
    "            'Miniskirt': 334,\n",
    "            'Helmet': 248,\n",
    "            'Kitchen Knife': 292,\n",
    "            'Shotgun': 457,\n",
    "            'Handgun': 238\n",
    "        }\n",
    "\n",
    "        # Style\n",
    "        style = ttk.Style()\n",
    "        style.configure('Big.TButton', padding=10, font=('Helvetica', 12))\n",
    "\n",
    "        # Création de l'interface\n",
    "        self.create_widgets()\n",
    "        self.last_logged_person = None  # Pour tracker la dernière personne enregistrée\n",
    "        self.csv_file = \"face_detection_logs.csv\"\n",
    "\n",
    "    def create_widgets(self):\n",
    "        main_frame = ttk.Frame(self.root, padding=\"20\")\n",
    "        main_frame.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))\n",
    "\n",
    "        # Titre\n",
    "        title_label = ttk.Label(main_frame,\n",
    "                              text=\"Système de Reconnaissance Faciale et d'Objets\",\n",
    "                              font=('Helvetica', 14, 'bold'), wraplength=400)\n",
    "        title_label.grid(row=0, column=0, pady=20)\n",
    "\n",
    "        # Boutons\n",
    "        register_btn = ttk.Button(main_frame, text=\"Enregistrer un nouveau visage\",\n",
    "                               command=self.show_register_dialog, style='Big.TButton')\n",
    "        register_btn.grid(row=1, column=0, pady=10, padx=20, sticky=tk.EW)\n",
    "\n",
    "        train_btn = ttk.Button(main_frame, text=\"Entraîner le modèle facial\",\n",
    "                             command=self.start_training, style='Big.TButton')\n",
    "        train_btn.grid(row=2, column=0, pady=10, padx=20, sticky=tk.EW)\n",
    "\n",
    "        load_yolo_btn = ttk.Button(main_frame, text=\"Charger le modèle YOLO\",\n",
    "                                 command=self.load_yolo_model, style='Big.TButton')\n",
    "        load_yolo_btn.grid(row=3, column=0, pady=10, padx=20, sticky=tk.EW)\n",
    "\n",
    "        recognize_btn = ttk.Button(main_frame, text=\"Lancer la reconnaissance\",\n",
    "                                 command=self.toggle_recognition, style='Big.TButton')\n",
    "        recognize_btn.grid(row=4, column=0, pady=10, padx=20, sticky=tk.EW)\n",
    "\n",
    "        analyze_img_btn = ttk.Button(main_frame, text=\"Analyser une image\",\n",
    "                                   command=self.analyze_image, style='Big.TButton')\n",
    "        analyze_img_btn.grid(row=5, column=0, pady=10, padx=20, sticky=tk.EW)\n",
    "\n",
    "        # Progress bar\n",
    "        self.progress_var = tk.DoubleVar()\n",
    "        self.progress = ttk.Progressbar(main_frame, variable=self.progress_var,\n",
    "                                      maximum=100, mode='determinate')\n",
    "        self.progress.grid(row=6, column=0, pady=10, sticky=tk.EW)\n",
    "\n",
    "        # Status\n",
    "        self.status_var = tk.StringVar(value=\"En attente...\")\n",
    "        status_label = ttk.Label(main_frame, textvariable=self.status_var,\n",
    "                               wraplength=400)\n",
    "        status_label.grid(row=7, column=0, pady=10)\n",
    "\n",
    "    def show_register_dialog(self):\n",
    "        \"\"\"Affiche une fenêtre de dialogue pour enregistrer un nouveau visage\"\"\"\n",
    "        dialog = tk.Toplevel(self.root)\n",
    "        dialog.title(\"Enregistrer un nouveau visage\")\n",
    "        dialog.geometry(\"300x150\")\n",
    "\n",
    "        ttk.Label(dialog, text=\"Prénom:\").grid(row=0, column=0, padx=5, pady=5)\n",
    "        prenom_var = tk.StringVar()\n",
    "        ttk.Entry(dialog, textvariable=prenom_var).grid(row=0, column=1, padx=5, pady=5)\n",
    "\n",
    "        ttk.Label(dialog, text=\"Nom:\").grid(row=1, column=0, padx=5, pady=5)\n",
    "        nom_var = tk.StringVar()\n",
    "        ttk.Entry(dialog, textvariable=nom_var).grid(row=1, column=1, padx=5, pady=5)\n",
    "\n",
    "        def validate():\n",
    "            prenom = prenom_var.get().strip()\n",
    "            nom = nom_var.get().strip()\n",
    "            if prenom and nom:\n",
    "                dialog.destroy()\n",
    "                self.capture_face(prenom, nom)\n",
    "            else:\n",
    "                messagebox.showerror(\"Erreur\", \"Veuillez remplir tous les champs\")\n",
    "\n",
    "        ttk.Button(dialog, text=\"Commencer la capture\",\n",
    "                  command=validate).grid(row=2, column=0, columnspan=2, pady=20)\n",
    "\n",
    "    def capture_face(self, prenom, nom):\n",
    "        \"\"\"Capture les images du visage pour l'enregistrement\"\"\"\n",
    "        # Créer le dossier pour enregistrer les images\n",
    "        folder_name = f\"dataset(test)/{prenom.capitalize()} {nom.capitalize()}\"\n",
    "        if not os.path.exists(folder_name):\n",
    "            os.makedirs(folder_name)\n",
    "\n",
    "        # Ouvrir la caméra\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        captured_images = 0\n",
    "        directions = [\"Regardez en face\", \"Regardez en haut\", \"Regardez vers la droite\",\n",
    "                     \"Regardez en bas\", \"Regardez vers la gauche\"]\n",
    "        images_per_direction = 1\n",
    "        total_images = len(directions) * images_per_direction\n",
    "\n",
    "        direction_index = 0\n",
    "\n",
    "        while captured_images < total_images:\n",
    "            current_direction = directions[direction_index]\n",
    "\n",
    "            # Pause de 3 secondes avec affichage\n",
    "            for i in range(3, 0, -1):\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                cv2.putText(frame, f\"{current_direction} dans {i} secondes\",\n",
    "                           (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "                cv2.imshow('Capturer le visage', frame)\n",
    "                cv2.waitKey(1000)\n",
    "\n",
    "            while captured_images < (direction_index + 1) * images_per_direction:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                faces = self.face_cascade.detectMultiScale(gray, scaleFactor=1.1,\n",
    "                                                         minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "                for (x, y, w, h) in faces:\n",
    "                    # Élargir la zone pour la tête\n",
    "                    x_head = max(0, x - int(0.2 * w))\n",
    "                    y_head = max(0, y - int(0.3 * h))\n",
    "                    w_head = min(frame.shape[1] - x_head, int(w * 1.4))\n",
    "                    h_head = min(frame.shape[0] - y_head, int(h * 1.6))\n",
    "\n",
    "                    head = frame[y_head:y_head+h_head, x_head:x_head+w_head]\n",
    "                    head_filename = f\"{folder_name}/head_{captured_images}.jpg\"\n",
    "                    cv2.imwrite(head_filename, head)\n",
    "                    captured_images += 1\n",
    "\n",
    "                    cv2.putText(frame, f\"Image {captured_images}/{total_images}\",\n",
    "                              (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                    cv2.rectangle(frame, (x_head, y_head),\n",
    "                                (x_head+w_head, y_head+h_head), (0, 255, 0), 2)\n",
    "\n",
    "                cv2.putText(frame, f\"Etape actuelle : {current_direction}\",\n",
    "                          (10, frame.shape[0] - 20),\n",
    "                          cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)\n",
    "\n",
    "                cv2.imshow('Capturer le visage', frame)\n",
    "\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    cap.release()\n",
    "                    cv2.destroyAllWindows()\n",
    "                    return\n",
    "\n",
    "            direction_index = (direction_index + 1) % len(directions)\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        messagebox.showinfo(\"Succès\",\n",
    "                          \"Enregistrement du visage terminé. Veuillez entraîner le modèle.\")\n",
    "\n",
    "    def load_models(self):\n",
    "        \"\"\"Charge les modèles nécessaires\"\"\"\n",
    "        try:\n",
    "            self.status_var.set(\"Chargement du modèle facial...\")\n",
    "            self.face_model = load_model(\"face_recognition_model.h5\", compile=False)\n",
    "            with open(\"label_map.pkl\", 'rb') as f:\n",
    "                self.label_map = pickle.load(f)\n",
    "            self.status_var.set(\"Modèle facial chargé\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Erreur\", f\"Erreur lors du chargement du modèle facial: {str(e)}\")\n",
    "            self.status_var.set(\"Erreur chargement modèle facial\")\n",
    "            return False\n",
    "\n",
    "    def load_yolo_model(self):\n",
    "        \"\"\"Charge le modèle YOLO\"\"\"\n",
    "        try:\n",
    "            self.status_var.set(\"Chargement du modèle YOLO...\")\n",
    "            logging.getLogger(\"ultralytics\").setLevel(logging.WARNING)\n",
    "            self.model_yolo = YOLO(\"yolov8n-oiv7.pt\", verbose=False)\n",
    "            messagebox.showinfo(\"Succès\", \"Modèle YOLO chargé avec succès!\")\n",
    "            self.status_var.set(\"Modèle YOLO chargé\")\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Erreur\", f\"Erreur lors du chargement de YOLO: {str(e)}\")\n",
    "            self.status_var.set(\"Erreur chargement YOLO\")\n",
    "\n",
    "    def detect_objects(self, frame):\n",
    "        \"\"\"Détecte les objets dans la frame\"\"\"\n",
    "        if self.model_yolo is None:\n",
    "            return []\n",
    "\n",
    "        old_stdout = sys.stdout\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "        results = self.model_yolo(frame, verbose=False)\n",
    "\n",
    "        sys.stdout = old_stdout\n",
    "\n",
    "        detections = []\n",
    "\n",
    "        for r in results:\n",
    "            boxes = r.boxes\n",
    "            for box in boxes:\n",
    "                cls_id = int(box.cls[0])\n",
    "                for nom_objet, id_classe in self.OBJETS_SURVEILLES.items():\n",
    "                    if cls_id == id_classe:\n",
    "                        x1, y1, x2, y2 = box.xyxy[0]\n",
    "                        confidence = float(box.conf[0])\n",
    "                        if confidence > 0.4:\n",
    "                            detections.append({\n",
    "                                'objet': nom_objet,\n",
    "                                'confiance': confidence,\n",
    "                                'coords': (int(x1), int(y1), int(x2), int(y2))\n",
    "                            })\n",
    "        return detections\n",
    "\n",
    "    def log_detection(self, personne, objets_interdits):\n",
    "        \"\"\"\n",
    "        Enregistre une détection dans le fichier CSV si ce n'est pas un doublon consécutif\n",
    "        \"\"\"\n",
    "        if personne == \"Inconnu\" or personne == self.last_logged_person:\n",
    "            return False\n",
    "\n",
    "        current_time = datetime.now()\n",
    "        date = current_time.strftime('%d/%m/%Y')\n",
    "        heure = current_time.strftime('%H:%M:%S')\n",
    "\n",
    "        objets_str = \"|\".join(objets_interdits) if objets_interdits else \"Aucun\"\n",
    "\n",
    "        with open(self.csv_file, 'a', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f, delimiter=';')\n",
    "            writer.writerow([date, heure, personne, objets_str, self.action, self.salle])\n",
    "\n",
    "        self.last_logged_person = personne\n",
    "        return True\n",
    "\n",
    "    def start_recognition(self):\n",
    "        \"\"\"Fonction de reconnaissance en temps réel avec logging\"\"\"\n",
    "        try:\n",
    "            # Charger le modèle de reconnaissance faciale\n",
    "            model = load_model(\"face_recognition_model.h5\", compile=False)\n",
    "            with open(\"label_map.pkl\", 'rb') as f:\n",
    "                label_map = pickle.load(f)\n",
    "\n",
    "            cap = cv2.VideoCapture(0)\n",
    "            face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "            last_predictions = []\n",
    "            PREDICTION_MEMORY = 5\n",
    "\n",
    "            while self.is_recognition_running:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "\n",
    "                # Détection d'objets\n",
    "                detections = self.detect_objects(frame)\n",
    "                objets_interdits = []\n",
    "                for detection in detections:\n",
    "                    if detection['objet'] in self.OBJETS_SURVEILLES:\n",
    "                        objets_interdits.append(detection['objet'])\n",
    "                    x1, y1, x2, y2 = detection['coords']\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "                    text = f\"{detection['objet']} ({detection['confiance']:.2f})\"\n",
    "                    cv2.putText(frame, text, (x1, y1-10),\n",
    "                              cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "\n",
    "                # Reconnaissance faciale\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "                for (x, y, w, h) in faces:\n",
    "                    margin = 20\n",
    "                    y1 = max(0, y - margin)\n",
    "                    y2 = min(frame.shape[0], y + h + margin)\n",
    "                    x1 = max(0, x - margin)\n",
    "                    x2 = min(frame.shape[1], x + w + margin)\n",
    "                    face_img = frame[y1:y2, x1:x2]\n",
    "\n",
    "                    try:\n",
    "                        embedding = DeepFace.represent(face_img, model_name=\"ArcFace\",\n",
    "                                                     enforce_detection=False)\n",
    "\n",
    "                        if embedding:\n",
    "                            embedding_array = np.array([embedding[0][\"embedding\"]])\n",
    "                            prediction = model.predict(embedding_array, verbose=0)\n",
    "                            predicted_class = np.argmax(prediction)\n",
    "                            confidence = prediction[0][predicted_class]\n",
    "\n",
    "                            # Système de lissage\n",
    "                            last_predictions.append((predicted_class, confidence))\n",
    "                            if len(last_predictions) > PREDICTION_MEMORY:\n",
    "                                last_predictions.pop(0)\n",
    "\n",
    "                            if len(last_predictions) >= 3:\n",
    "                                class_counts = {}\n",
    "                                for pred_class, conf in last_predictions:\n",
    "                                    if pred_class not in class_counts:\n",
    "                                        class_counts[pred_class] = []\n",
    "                                    class_counts[pred_class].append(conf)\n",
    "\n",
    "                                most_common_class = max(class_counts.items(),\n",
    "                                                      key=lambda x: (len(x[1]),\n",
    "                                                                   sum(x[1])/len(x[1])))[0]\n",
    "                                avg_confidence = np.mean(class_counts[most_common_class])\n",
    "\n",
    "                                predicted_class = most_common_class\n",
    "                                confidence = avg_confidence\n",
    "\n",
    "                            predicted_name = label_map[predicted_class]\n",
    "                            if confidence < 0.75:  # Seuil de confiance\n",
    "                                predicted_name = \"Inconnu\"\n",
    "                                color = (0, 0, 255)  # Rouge pour inconnu\n",
    "                                text = predicted_name\n",
    "                            else:\n",
    "                                predicted_name = label_map[predicted_class]\n",
    "                                color = (0, int(255 * confidence), 0)\n",
    "                                text = f\"{predicted_name} ({confidence:.2f})\"\n",
    "                                self.log_detection(predicted_name, objets_interdits)\n",
    "\n",
    "                            cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "                            cv2.putText(frame, text, (x, y-10),\n",
    "                                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "                    except Exception as e:\n",
    "                        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "\n",
    "                cv2.imshow('Système de reconnaissance', frame)\n",
    "\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Erreur\", f\"Erreur pendant la reconnaissance: {str(e)}\")\n",
    "            self.status_var.set(\"Erreur pendant la reconnaissance\")\n",
    "        finally:\n",
    "            self.is_recognition_running = False\n",
    "\n",
    "    def analyze_image(self):\n",
    "        \"\"\"Analyse une image sélectionnée\"\"\"\n",
    "        # Ouvrir le sélecteur de fichier\n",
    "        file_path = filedialog.askopenfilename(\n",
    "            title=\"Sélectionner une image\",\n",
    "            filetypes=[(\"Images\", \"*.jpg *.jpeg *.png *.bmp\")]\n",
    "        )\n",
    "\n",
    "        if not file_path:\n",
    "            return\n",
    "\n",
    "        # Vérifier que les modèles sont chargés\n",
    "        if not self.load_models():\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            # Lire l'image\n",
    "            frame = cv2.imread(file_path)\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # Convertir en RGB pour DeepFace\n",
    "\n",
    "            # Détection d'objets\n",
    "            detections = self.detect_objects(frame)\n",
    "            for detection in detections:\n",
    "                x1, y1, x2, y2 = detection['coords']\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "                text = f\"{detection['objet']} ({detection['confiance']:.2f})\"\n",
    "                cv2.putText(frame, text, (x1, y1-10),\n",
    "                          cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "\n",
    "            # Reconnaissance faciale\n",
    "            face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades +\n",
    "                                               'haarcascade_frontalface_default.xml')\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "            faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "            for (x, y, w, h) in faces:\n",
    "                margin = 20\n",
    "                y1 = max(0, y - margin)\n",
    "                y2 = min(frame.shape[0], y + h + margin)\n",
    "                x1 = max(0, x - margin)\n",
    "                x2 = min(frame.shape[1], x + w + margin)\n",
    "                face_img = frame[y1:y2, x1:x2]\n",
    "\n",
    "                try:\n",
    "                    embedding = DeepFace.represent(face_img, model_name=\"ArcFace\",\n",
    "                                                 enforce_detection=False)\n",
    "\n",
    "                    if embedding:\n",
    "                        embedding_array = np.array([embedding[0][\"embedding\"]])\n",
    "                        prediction = self.face_model.predict(embedding_array, verbose=0)\n",
    "                        predicted_class = np.argmax(prediction)\n",
    "                        confidence = prediction[0][predicted_class]\n",
    "\n",
    "                        predicted_name = self.label_map[predicted_class]\n",
    "                        if confidence < 0.75:  # Seuil de confiance\n",
    "                            predicted_name = \"Inconnu\"\n",
    "                            color = (0, 0, 255)  # Rouge pour inconnu\n",
    "                            text = predicted_name\n",
    "                        else:\n",
    "                            predicted_name = self.label_map[predicted_class]\n",
    "                            color = (0, int(255 * confidence), 0)\n",
    "                            text = f\"{predicted_name} ({confidence:.2f})\"\n",
    "\n",
    "                        cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "\n",
    "                        cv2.putText(frame, text, (x, y-10),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "                except Exception as e:\n",
    "                    cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "\n",
    "            # Afficher l'image analysée\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)  # Reconvertir en BGR pour l'affichage\n",
    "            cv2.imshow('Analyse de l\\'image', frame)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Erreur\", f\"Erreur pendant l'analyse de l'image: {str(e)}\")\n",
    "            self.status_var.set(\"Erreur pendant l'analyse\")\n",
    "\n",
    "    def toggle_recognition(self):\n",
    "        \"\"\"Démarre ou arrête la reconnaissance\"\"\"\n",
    "        if not self.is_recognition_running:\n",
    "            if not os.path.exists(\"face_recognition_model.h5\"):\n",
    "                messagebox.showerror(\"Erreur\", \"Le modèle facial n'a pas été entraîné!\")\n",
    "                return\n",
    "\n",
    "            if self.model_yolo is None:\n",
    "                messagebox.showwarning(\"Attention\",\n",
    "                                     \"Le modèle YOLO n'est pas chargé. \" +\n",
    "                                     \"Seule la reconnaissance faciale sera active.\")\n",
    "\n",
    "            self.is_recognition_running = True\n",
    "            self.status_var.set(\"Reconnaissance en cours...\")\n",
    "            threading.Thread(target=self.start_recognition, daemon=True).start()\n",
    "        else:\n",
    "            self.is_recognition_running = False\n",
    "            self.status_var.set(\"Reconnaissance arrêtée\")\n",
    "\n",
    "    def train_model(self):\n",
    "        \"\"\"Fonction d'entraînement du modèle\"\"\"\n",
    "        try:\n",
    "            self.status_var.set(\"Chargement des données...\")\n",
    "            db_path = \"dataset(test)\"\n",
    "            embeddings = []\n",
    "            labels = []\n",
    "            label_map = {}\n",
    "\n",
    "            # Liste tous les dossiers de personnes\n",
    "            all_persons = sorted([d for d in os.listdir(db_path)\n",
    "                                if os.path.isdir(os.path.join(db_path, d))])\n",
    "            total_persons = len(all_persons)\n",
    "\n",
    "            for idx, person in enumerate(all_persons):\n",
    "                person_path = os.path.join(db_path, person)\n",
    "                label_map[idx] = person\n",
    "\n",
    "                person_progress = (idx / total_persons) * 50  # Première moitié de la progress bar\n",
    "                self.progress_var.set(person_progress)\n",
    "                self.status_var.set(f\"Traitement des images de {person}...\")\n",
    "\n",
    "                for image_name in os.listdir(person_path):\n",
    "                    image_path = os.path.join(person_path, image_name)\n",
    "                    try:\n",
    "                        embedding = DeepFace.represent(image_path, model_name=\"ArcFace\",\n",
    "                                                     enforce_detection=False)\n",
    "                        embeddings.append(embedding[0][\"embedding\"])\n",
    "                        labels.append(idx)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Erreur avec {image_path}: {e}\")\n",
    "\n",
    "            embeddings = np.array(embeddings)\n",
    "            labels = np.array(labels)\n",
    "\n",
    "            # Préparation des données\n",
    "            self.status_var.set(\"Préparation des données...\")\n",
    "            X_train, X_test, y_train, y_test = train_test_split(embeddings, labels,\n",
    "                                                               test_size=0.2, random_state=42)\n",
    "            y_train = to_categorical(y_train, num_classes=len(label_map))\n",
    "            y_test = to_categorical(y_test, num_classes=len(label_map))\n",
    "\n",
    "            # Création et compilation du modèle\n",
    "            self.status_var.set(\"Création du modèle...\")\n",
    "            model = Sequential([\n",
    "                Dense(128, input_shape=(embeddings.shape[1],), activation='relu'),\n",
    "                Dropout(0.5),\n",
    "                Dense(64, activation='relu'),\n",
    "                Dropout(0.5),\n",
    "                Dense(len(label_map), activation='softmax')\n",
    "            ])\n",
    "\n",
    "            model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "            # Entraînement\n",
    "            self.status_var.set(\"Entraînement en cours...\")\n",
    "            epochs = 100\n",
    "            for epoch in range(epochs):\n",
    "                model.fit(X_train, y_train, epochs=1, batch_size=16,\n",
    "                         validation_data=(X_test, y_test), verbose=0)\n",
    "                progress = 50 + (epoch / epochs) * 50  # Deuxième moitié de la progress bar\n",
    "                self.progress_var.set(progress)\n",
    "                self.status_var.set(f\"Entraînement: {epoch+1}/{epochs} epochs\")\n",
    "\n",
    "            # Sauvegarde\n",
    "            model.save(\"face_recognition_model.h5\")\n",
    "            with open(\"label_map.pkl\", 'wb') as f:\n",
    "                pickle.dump(label_map, f)\n",
    "\n",
    "            self.progress_var.set(100)\n",
    "            self.status_var.set(\"Entraînement terminé!\")\n",
    "            messagebox.showinfo(\"Succès\", \"Le modèle a été entraîné avec succès!\")\n",
    "\n",
    "        except Exception as e:\n",
    "            self.status_var.set(\"Erreur pendant l'entraînement\")\n",
    "            messagebox.showerror(\"Erreur\", f\"Erreur pendant l'entraînement: {str(e)}\")\n",
    "        finally:\n",
    "            self.training_in_progress = False\n",
    "            self.progress_var.set(0)\n",
    "\n",
    "    def start_training(self):\n",
    "            \"\"\"Démarre l'entraînement dans un thread séparé\"\"\"\n",
    "            if not self.training_in_progress:\n",
    "                self.training_in_progress = True\n",
    "                threading.Thread(target=self.train_model, daemon=True).start()\n",
    "            else:\n",
    "                messagebox.showwarning(\"En cours\", \"L'entraînement est déjà en cours!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    login = LoginWindow()\n",
    "    login.run()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\waute\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T18:11:04.561546Z",
     "start_time": "2025-01-14T18:11:04.545412Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
