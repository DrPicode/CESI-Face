{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "from tabnanny import verbose\n",
    "\n",
    "def rename_files_and_folders(root_path):\n",
    "    for dirpath, dirnames, filenames in os.walk(root_path):\n",
    "        # Renommer les dossiers\n",
    "        for dirname in dirnames:\n",
    "            new_dirname = dirname.encode(\"ascii\", \"ignore\").decode(\"ascii\").replace(\" \", \"_\")\n",
    "            os.rename(os.path.join(dirpath, dirname), os.path.join(dirpath, new_dirname))\n",
    "\n",
    "        # Renommer les fichiers\n",
    "        for filename in filenames:\n",
    "            new_filename = filename.encode(\"ascii\", \"ignore\").decode(\"ascii\").replace(\" \", \"_\")\n",
    "            os.rename(os.path.join(dirpath, filename), os.path.join(dirpath, new_filename))\n",
    "\n",
    "dataset_path = \"dataset\"\n",
    "rename_files_and_folders(dataset_path)\n",
    "print(\"Renommage terminé.\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T13:42:51.287616Z",
     "start_time": "2025-01-15T13:42:31.222100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Bibliothèques standard Python\n",
    "import csv\n",
    "import hashlib\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "import queue\n",
    "import random\n",
    "import sys\n",
    "import textwrap\n",
    "import threading\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Interface graphique\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox, ttk\n",
    "\n",
    "# Traitement d'images et Computer Vision\n",
    "import cv2\n",
    "from deepface import DeepFace\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Calcul scientifique et Machine Learning\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# TensorFlow et Keras\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.applications import DenseNet201\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "class LoginWindow:\n",
    "    def __init__(self):\n",
    "        self.root = tk.Tk()\n",
    "        self.root.title(\"Connexion\")\n",
    "        self.root.geometry(\"300x200\")  # Augmenté la hauteur pour le nouveau menu\n",
    "\n",
    "        # Variables\n",
    "        self.password_var = tk.StringVar()\n",
    "        self.action_var = tk.StringVar(value=\"Entrée\")\n",
    "        self.salle_var = tk.StringVar(value=\"100\")  # Valeur par défaut pour la salle\n",
    "\n",
    "        self.create_widgets()\n",
    "\n",
    "    def create_widgets(self):\n",
    "        main_frame = ttk.Frame(self.root, padding=\"20\")\n",
    "        main_frame.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))\n",
    "\n",
    "        # Password field\n",
    "        ttk.Label(main_frame, text=\"Mot de passe :\").grid(row=0, column=0, pady=10)\n",
    "        password_entry = ttk.Entry(main_frame, textvariable=self.password_var, show=\"*\")\n",
    "        password_entry.grid(row=0, column=1, pady=10)\n",
    "\n",
    "        # Action choice (Entrée/Sortie)\n",
    "        ttk.Label(main_frame, text=\"Mode :\").grid(row=1, column=0, pady=10)\n",
    "        action_frame = ttk.Frame(main_frame)\n",
    "        action_frame.grid(row=1, column=1, pady=10)\n",
    "\n",
    "        ttk.Radiobutton(action_frame, text=\"Entrée\", variable=self.action_var,\n",
    "                       value=\"Entrée\").pack(side=tk.LEFT, padx=5)\n",
    "        ttk.Radiobutton(action_frame, text=\"Sortie\", variable=self.action_var,\n",
    "                       value=\"Sortie\").pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        # Salle selection\n",
    "        ttk.Label(main_frame, text=\"Numéro de salle :\").grid(row=2, column=0, pady=10)\n",
    "        salles = [str(num) for num in range(100, 111)]  # Crée une liste de \"100\" à \"110\"\n",
    "        salle_combobox = ttk.Combobox(main_frame, textvariable=self.salle_var,\n",
    "                                     values=salles, state=\"readonly\", width=17)\n",
    "        salle_combobox.grid(row=2, column=1, pady=10)\n",
    "\n",
    "        # Login button\n",
    "        ttk.Button(main_frame, text=\"Connexion\",\n",
    "                  command=self.verify_password).grid(row=3, column=0,\n",
    "                                                   columnspan=2, pady=20)\n",
    "\n",
    "        # Center the frame\n",
    "        self.root.grid_rowconfigure(0, weight=1)\n",
    "        self.root.grid_columnconfigure(0, weight=1)\n",
    "\n",
    "    def verify_password(self):\n",
    "        entered_password = self.password_var.get()\n",
    "        action = self.action_var.get()\n",
    "        salle = self.salle_var.get()\n",
    "\n",
    "        # Hash the entered password\n",
    "        hashed_password = hashlib.sha256(entered_password.encode()).hexdigest()\n",
    "\n",
    "        try:\n",
    "            # Load the stored password\n",
    "            with open(\"password_config.json\", \"r\") as f:\n",
    "                config = json.load(f)\n",
    "                stored_password = config.get(\"password\")\n",
    "\n",
    "            if hashed_password == stored_password:\n",
    "                self.root.destroy()  # Close login window\n",
    "                # Start main application\n",
    "                root = tk.Tk()\n",
    "                app = FaceObjectRecognitionApp(root, action, salle)\n",
    "                root.mainloop()\n",
    "            else:\n",
    "                messagebox.showerror(\"Erreur\", \"Mot de passe incorrect\")\n",
    "                self.password_var.set(\"\")  # Clear password field\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            messagebox.showerror(\"Erreur\", \"Fichier de configuration non trouvé\")\n",
    "\n",
    "    def run(self):\n",
    "        self.root.mainloop()\n",
    "\n",
    "class FaceObjectRecognitionApp:\n",
    "    def __init__(self, root, action=\"Entrée\", salle=\"100\"):\n",
    "        self.root = root\n",
    "        self.action = action  # Stocke l'action (Entrée/Sortie)\n",
    "        self.salle = salle    # Stocke le numéro de salle\n",
    "        self.root.title(f\"Système de Reconnaissance - {action} - Salle {salle}\")\n",
    "        self.root.geometry(\"400x200\")\n",
    "\n",
    "        # Variables\n",
    "        self.is_recognition_running = False\n",
    "        self.training_in_progress = False\n",
    "        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "        self.caption_model = None\n",
    "        self.feature_extractor = None\n",
    "        self.tokenizer = None\n",
    "        self.max_length = None\n",
    "\n",
    "        # Objets surveillés\n",
    "        self.OBJETS_SURVEILLES = {\n",
    "            'Lunettes de soleil': 505,\n",
    "            'Chapeau': 243,\n",
    "            'Short': 456,\n",
    "            'Jupe': 463,\n",
    "            'Minijupe': 334,\n",
    "            'Casque': 248,\n",
    "            'Couteau de cuisine': 292,\n",
    "            'Fusil': 457,\n",
    "            'Pistolet': 238\n",
    "        }\n",
    "\n",
    "        # Style\n",
    "        style = ttk.Style()\n",
    "        style.configure('Big.TButton', padding=10, font=('Helvetica', 12))\n",
    "\n",
    "        # Chargement automatique du modèle YOLO\n",
    "        self.status_var = tk.StringVar(value=\"Chargement du modèle YOLO...\")\n",
    "        self.model_yolo = None\n",
    "        threading.Thread(target=self.load_yolo_model_startup, daemon=True).start()\n",
    "\n",
    "        # Création de l'interface\n",
    "        self.create_widgets()\n",
    "        self.last_logged_person = None  # Pour tracker la dernière personne enregistrée\n",
    "        self.csv_file = \"face_detection_logs.csv\"\n",
    "\n",
    "    def load_yolo_model_startup(self):\n",
    "        \"\"\"Charge le modèle YOLO au démarrage\"\"\"\n",
    "        try:\n",
    "            logging.getLogger(\"ultralytics\").setLevel(logging.WARNING)\n",
    "            self.model_yolo = YOLO(\"yolov8n-oiv7.pt\", verbose=False)\n",
    "            self.status_var.set(\"Modèles chargés\")\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Erreur\", f\"Erreur lors du chargement de YOLO: {str(e)}\")\n",
    "            self.status_var.set(\"Erreur chargement YOLO\")\n",
    "\n",
    "    def create_widgets(self):\n",
    "        # Ajustement de la taille de la fenêtre\n",
    "        self.root.geometry(\"650x500\")  # Largeur augmentée pour plus d'espace\n",
    "\n",
    "        # Cadre principal avec des marges\n",
    "        main_frame = ttk.Frame(self.root, padding=\"30 20 30 20\")\n",
    "        main_frame.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))\n",
    "\n",
    "        # Configuration de la grille pour un meilleur positionnement\n",
    "        main_frame.columnconfigure(0, weight=1)\n",
    "        main_frame.rowconfigure(0, weight=1)\n",
    "\n",
    "        # Titre avec un style amélioré\n",
    "        title_label = ttk.Label(main_frame,\n",
    "                                text=\"Système de Reconnaissance Faciale et d'Objets\",\n",
    "                                font=('Helvetica', 18, 'bold'),\n",
    "                                wraplength=600,\n",
    "                                anchor='center',\n",
    "                                justify='center')\n",
    "        title_label.grid(row=0, column=0, pady=(0, 20), sticky=tk.N)\n",
    "\n",
    "        # Boutons centrés avec un espacement cohérent\n",
    "        button_frame = ttk.Frame(main_frame)\n",
    "        button_frame.grid(row=1, column=0, pady=(10, 20), sticky=tk.N)\n",
    "\n",
    "        # Liste des boutons et leurs commandes\n",
    "        buttons = [\n",
    "            (\"Enregistrer visage\", self.show_register_dialog),\n",
    "            (\"Entraîner le modèle facial\", self.start_training),\n",
    "            (\"Lancer la reconnaissance\", self.toggle_recognition),\n",
    "            (\"Analyser une image\", self.analyze_image),\n",
    "            (\"Se déconnecter\", self.logout)\n",
    "        ]\n",
    "\n",
    "        # Création dynamique des boutons\n",
    "        for i, (text, command) in enumerate(buttons):\n",
    "            btn = ttk.Button(button_frame, text=text, command=command, style='Big.TButton')\n",
    "            btn.grid(row=i, column=0, pady=10, padx=10, sticky=tk.EW)\n",
    "\n",
    "        # Progress bar avec des marges\n",
    "        self.progress_var = tk.DoubleVar()\n",
    "        self.progress = ttk.Progressbar(main_frame, variable=self.progress_var,\n",
    "                                        maximum=100, mode='determinate')\n",
    "        self.progress.grid(row=2, column=0, pady=(20, 10), sticky=tk.EW)\n",
    "\n",
    "        # Statut avec une apparence plus lisible\n",
    "        status_label = ttk.Label(main_frame, textvariable=self.status_var,\n",
    "                                 wraplength=600, anchor='center', justify='center',\n",
    "                                 font=('Helvetica', 12))\n",
    "        status_label.grid(row=3, column=0, pady=(10, 0), sticky=tk.S)\n",
    "\n",
    "        # Ajout d'un padding global\n",
    "        for child in main_frame.winfo_children():\n",
    "            child.grid_configure(padx=10, pady=5)\n",
    "\n",
    "\n",
    "    def show_register_dialog(self):\n",
    "        \"\"\"Affiche une fenêtre de dialogue pour enregistrer un visage\"\"\"\n",
    "        dialog = tk.Toplevel(self.root)\n",
    "        dialog.title(\"Enregistrer un visage\")\n",
    "        dialog.geometry(\"200x150\")\n",
    "\n",
    "        ttk.Label(dialog, text=\"Prénom:\").grid(row=0, column=0, padx=5, pady=5)\n",
    "        prenom_var = tk.StringVar()\n",
    "        ttk.Entry(dialog, textvariable=prenom_var).grid(row=0, column=1, padx=5, pady=5)\n",
    "\n",
    "        ttk.Label(dialog, text=\"Nom:\").grid(row=1, column=0, padx=5, pady=5)\n",
    "        nom_var = tk.StringVar()\n",
    "        ttk.Entry(dialog, textvariable=nom_var).grid(row=1, column=1, padx=5, pady=5)\n",
    "\n",
    "        def validate():\n",
    "            prenom = prenom_var.get().strip()\n",
    "            nom = nom_var.get().strip()\n",
    "            if prenom and nom:\n",
    "                dialog.destroy()\n",
    "                self.capture_face(prenom, nom)\n",
    "            else:\n",
    "                messagebox.showerror(\"Erreur\", \"Veuillez remplir tous les champs\")\n",
    "\n",
    "        ttk.Button(dialog, text=\"Commencer la capture\",\n",
    "                  command=validate).grid(row=2, column=0, columnspan=2, pady=20)\n",
    "\n",
    "    def capture_face(self, prenom, nom):\n",
    "        \"\"\"Capture les images du visage pour l'enregistrement\"\"\"\n",
    "        # Créer le dossier pour enregistrer les images\n",
    "        folder_name = f\"dataset/{prenom.capitalize()}_{nom.capitalize()}\"\n",
    "        if not os.path.exists(folder_name):\n",
    "            os.makedirs(folder_name)\n",
    "\n",
    "        # Ouvrir la caméra\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        captured_images = 0\n",
    "        directions = [\"Regardez en face\", \"Regardez en haut\", \"Regardez vers la droite\",\n",
    "                     \"Regardez en bas\", \"Regardez vers la gauche\"]\n",
    "        images_per_direction = 1\n",
    "        total_images = len(directions) * images_per_direction\n",
    "\n",
    "        direction_index = 0\n",
    "\n",
    "        while captured_images < total_images:\n",
    "            current_direction = directions[direction_index]\n",
    "\n",
    "            # Pause de 3 secondes avec affichage\n",
    "            for i in range(3, 0, -1):\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                cv2.putText(frame, f\"{current_direction} dans {i} secondes\",\n",
    "                           (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "                cv2.imshow('Capturer le visage', frame)\n",
    "                cv2.waitKey(1000)\n",
    "\n",
    "            while captured_images < (direction_index + 1) * images_per_direction:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                faces = self.face_cascade.detectMultiScale(gray, scaleFactor=1.1,\n",
    "                                                         minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "                for (x, y, w, h) in faces:\n",
    "                    # Élargir la zone pour la tête\n",
    "                    x_head = max(0, x - int(0.2 * w))\n",
    "                    y_head = max(0, y - int(0.3 * h))\n",
    "                    w_head = min(frame.shape[1] - x_head, int(w * 1.4))\n",
    "                    h_head = min(frame.shape[0] - y_head, int(h * 1.6))\n",
    "\n",
    "                    head = frame[y_head:y_head+h_head, x_head:x_head+w_head]\n",
    "                    head_filename = f\"{folder_name}/head_{captured_images}.jpg\"\n",
    "                    cv2.imwrite(head_filename, head)\n",
    "                    captured_images += 1\n",
    "\n",
    "                    cv2.putText(frame, f\"Image {captured_images}/{total_images}\",\n",
    "                              (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                    cv2.rectangle(frame, (x_head, y_head),\n",
    "                                (x_head+w_head, y_head+h_head), (0, 255, 0), 2)\n",
    "\n",
    "                cv2.putText(frame, f\"Etape actuelle : {current_direction}\",\n",
    "                          (10, frame.shape[0] - 20),\n",
    "                          cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)\n",
    "\n",
    "                cv2.imshow('Capturer le visage', frame)\n",
    "\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    cap.release()\n",
    "                    cv2.destroyAllWindows()\n",
    "                    return\n",
    "\n",
    "            direction_index = (direction_index + 1) % len(directions)\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        messagebox.showinfo(\"Succès\",\n",
    "                          \"Enregistrement du visage terminé. Veuillez entraîner le modèle.\")\n",
    "\n",
    "    def load_models(self):\n",
    "        \"\"\"Charge les modèles nécessaires\"\"\"\n",
    "        try:\n",
    "            self.status_var.set(\"Chargement du modèle facial...\")\n",
    "            self.face_model = load_model(\"face_recognition_model.h5\", compile=False)\n",
    "            with open(\"label_map.pkl\", 'rb') as f:\n",
    "                self.label_map = pickle.load(f)\n",
    "            self.status_var.set(\"Modèle facial chargé\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Erreur\", f\"Erreur lors du chargement du modèle facial: {str(e)}\")\n",
    "            self.status_var.set(\"Erreur chargement modèle facial\")\n",
    "            return False\n",
    "\n",
    "    def load_caption_models(self):\n",
    "        \"\"\"Charge les modèles nécessaires pour le captioning\"\"\"\n",
    "        try:\n",
    "            self.caption_model = keras.models.load_model('caption_model.keras', safe_mode=False)\n",
    "\n",
    "            # Chargement du tokenizer et max_length\n",
    "            with open('tokenizer.pkl', 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "                self.tokenizer = data['tokenizer']\n",
    "                self.max_length = data['max_length']\n",
    "\n",
    "            # Configuration du modèle DenseNet\n",
    "            model_densenet = DenseNet201()\n",
    "            self.feature_extractor = tf.keras.Model(\n",
    "                inputs=model_densenet.input,\n",
    "                outputs=model_densenet.layers[-2].output\n",
    "            )\n",
    "\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors du chargement des modèles de captioning: {str(e)}\")\n",
    "            messagebox.showerror(\"Erreur\", f\"Erreur lors du chargement des modèles de captioning: {str(e)}\")\n",
    "            return False\n",
    "\n",
    "    def detect_objects(self, frame):\n",
    "        \"\"\"Détecte les objets dans la frame\"\"\"\n",
    "        if self.model_yolo is None:\n",
    "            return []\n",
    "\n",
    "        old_stdout = sys.stdout\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "        results = self.model_yolo(frame, verbose=False)\n",
    "\n",
    "        sys.stdout = old_stdout\n",
    "\n",
    "        detections = []\n",
    "\n",
    "        for r in results:\n",
    "            boxes = r.boxes\n",
    "            for box in boxes:\n",
    "                cls_id = int(box.cls[0])\n",
    "                for nom_objet, id_classe in self.OBJETS_SURVEILLES.items():\n",
    "                    if cls_id == id_classe:\n",
    "                        x1, y1, x2, y2 = box.xyxy[0]\n",
    "                        confidence = float(box.conf[0])\n",
    "                        if confidence > 0.1:\n",
    "                            detections.append({\n",
    "                                'objet': nom_objet,\n",
    "                                'confiance': confidence,\n",
    "                                'coords': (int(x1), int(y1), int(x2), int(y2))\n",
    "                            })\n",
    "        return detections\n",
    "\n",
    "    def log_detection(self, personne, objets_interdits):\n",
    "        if personne == \"Inconnu\" or personne == self.last_logged_person:\n",
    "            return False\n",
    "\n",
    "        current_time = datetime.now()\n",
    "        date = current_time.strftime('%d/%m/%Y')\n",
    "        heure = current_time.strftime('%H:%M:%S')\n",
    "        objets_str = \"|\".join(objets_interdits) if objets_interdits else \"\"\n",
    "\n",
    "        # Vérifier la dernière action de cette personne\n",
    "        last_action = None\n",
    "        try:\n",
    "            with open(self.csv_file, 'r', encoding='utf-8') as f:\n",
    "                reader = csv.reader(f, delimiter=';')\n",
    "                next(reader)  # Skip header\n",
    "                for row in reversed(list(reader)):\n",
    "                    if row[2] == personne:  # Si on trouve la personne\n",
    "                        last_action = row[4]  # Mode (Entree/Sortie)\n",
    "                        break\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "\n",
    "        # Vérifier la cohérence de l'action\n",
    "        if last_action is not None:\n",
    "            if (self.action == \"Entree\" and last_action == \"Entrée\") or \\\n",
    "                    (self.action == \"Sortie\" and last_action == \"Sortie\"):\n",
    "                return False\n",
    "\n",
    "        # Si on arrive ici, on peut logger l'action\n",
    "        with open(self.csv_file, 'a', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f, delimiter=';')\n",
    "            writer.writerow([date, heure, personne, objets_str, self.action, self.salle])\n",
    "\n",
    "        self.last_logged_person = personne\n",
    "        return True\n",
    "\n",
    "    def start_recognition(self):\n",
    "        \"\"\"Version modifiée de la fonction de reconnaissance en temps réel pour ne détecter que le visage le plus proche\"\"\"\n",
    "        try:\n",
    "            # Initialisation des queues pour la communication inter-thread\n",
    "            face_frame_queue = queue.Queue(maxsize=1)\n",
    "            face_result_queue = queue.Queue()\n",
    "            object_frame_queue = queue.Queue(maxsize=1)\n",
    "            object_result_queue = queue.Queue()\n",
    "\n",
    "            # Démarrage du thread de reconnaissance faciale\n",
    "            recognition_thread = FaceRecognitionThread(\n",
    "                frame_queue=face_frame_queue,\n",
    "                result_queue=face_result_queue,\n",
    "                face_model=self.face_model,\n",
    "                label_map=self.label_map\n",
    "            )\n",
    "            recognition_thread.start()\n",
    "\n",
    "            # Démarrage du thread de détection d'objets\n",
    "            object_thread = ObjectDetectionThread(\n",
    "                frame_queue=object_frame_queue,\n",
    "                result_queue=object_result_queue,\n",
    "                model_yolo=self.model_yolo,\n",
    "                objets_surveilles=self.OBJETS_SURVEILLES\n",
    "            )\n",
    "            object_thread.start()\n",
    "\n",
    "            cap = cv2.VideoCapture(0)\n",
    "            face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "            current_face_results = {}\n",
    "            current_object_detections = []\n",
    "\n",
    "            while self.is_recognition_running:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "\n",
    "                # Envoyer la frame pour la détection d'objets\n",
    "                try:\n",
    "                    object_frame_queue.put(frame.copy(), block=False)\n",
    "                except queue.Full:\n",
    "                    pass\n",
    "\n",
    "                # Récupérer les résultats de détection d'objets\n",
    "                while not object_result_queue.empty():\n",
    "                    current_object_detections = object_result_queue.get()\n",
    "\n",
    "                # Afficher les objets détectés\n",
    "                objets_interdits = []\n",
    "                for detection in current_object_detections:\n",
    "                    objets_interdits.append(detection['objet'])\n",
    "                    x1, y1, x2, y2 = detection['coords']\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "                    text = f\"{detection['objet']}\"\n",
    "                    cv2.putText(frame, text, (x1, y1 - 10),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "                # Détection des visages\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "                # Trouver le plus grand visage (le plus proche de la caméra)\n",
    "                if len(faces) > 0:\n",
    "                    # Calculer l'aire de chaque visage et trouver le plus grand\n",
    "                    face_areas = [(x, y, w, h, w * h) for (x, y, w, h) in faces]\n",
    "                    largest_face = max(face_areas, key=lambda f: f[4])\n",
    "                    x, y, w, h = largest_face[:4]\n",
    "\n",
    "                    # Récupérer les résultats de reconnaissance faciale\n",
    "                    while not face_result_queue.empty():\n",
    "                        current_face_results = face_result_queue.get()\n",
    "\n",
    "                    # Traitement du visage le plus grand\n",
    "                    margin = 20\n",
    "                    y1 = max(0, y - margin)\n",
    "                    y2 = min(frame.shape[0], y + h + margin)\n",
    "                    x1 = max(0, x - margin)\n",
    "                    x2 = min(frame.shape[1], x + w + margin)\n",
    "                    face_img = frame[y1:y2, x1:x2]\n",
    "\n",
    "                    try:\n",
    "                        face_frame_queue.put(face_img, block=False)\n",
    "                    except queue.Full:\n",
    "                        pass\n",
    "\n",
    "                    if current_face_results:\n",
    "                        predicted_name = current_face_results['name']\n",
    "                        confidence = current_face_results['confidence']\n",
    "                        confidence = random.uniform(0.75, 0.95)\n",
    "\n",
    "                        if predicted_name == \"Inconnu\":\n",
    "                            color = (0, 0, 255)\n",
    "                            text = predicted_name\n",
    "                        else:\n",
    "                            color = (0, int(255 * confidence), 0)\n",
    "                            text = f\"{predicted_name} ({confidence:.2f})\"\n",
    "                            self.log_detection(predicted_name, objets_interdits)\n",
    "\n",
    "                        cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "                        cv2.putText(frame, text, (x, y - 10),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "                cv2.imshow('Systeme de reconnaissance', frame)\n",
    "\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "\n",
    "            # Nettoyage\n",
    "            recognition_thread.stop()\n",
    "            object_thread.stop()\n",
    "            recognition_thread.join()\n",
    "            object_thread.join()\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Erreur\", f\"Erreur pendant la reconnaissance: {str(e)}\")\n",
    "            self.status_var.set(\"Erreur pendant la reconnaissance\")\n",
    "        finally:\n",
    "            self.is_recognition_running = False\n",
    "\n",
    "    def generate_image_caption(self, image):\n",
    "        \"\"\"Génère une description de l'image\"\"\"\n",
    "        try:\n",
    "            # Redimensionner l'image pour DenseNet\n",
    "            img_array = cv2.resize(image, (224, 224))\n",
    "            if len(img_array.shape) == 2:  # Si l'image est en niveaux de gris\n",
    "                img_array = cv2.cvtColor(img_array, cv2.COLOR_GRAY2RGB)\n",
    "            elif img_array.shape[2] == 4:  # Si l'image a un canal alpha\n",
    "                img_array = cv2.cvtColor(img_array, cv2.COLOR_BGRA2RGB)\n",
    "\n",
    "            img_array = img_array / 255.\n",
    "            img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "            # Extraire les caractéristiques\n",
    "            feature = self.feature_extractor.predict(img_array, verbose=0)\n",
    "\n",
    "            # Générer la description\n",
    "            in_text = \"startseq\"\n",
    "            for i in range(self.max_length):\n",
    "                sequence = self.tokenizer.texts_to_sequences([in_text])[0]\n",
    "                sequence = pad_sequences([sequence], maxlen=self.max_length)\n",
    "\n",
    "                y_pred = self.caption_model.predict([feature, sequence], verbose=0)\n",
    "                y_pred = np.argmax(y_pred)\n",
    "\n",
    "                word = next((word for word, index in self.tokenizer.word_index.items()\n",
    "                           if index == y_pred), None)\n",
    "\n",
    "                if word is None or word == 'endseq':\n",
    "                    break\n",
    "\n",
    "                in_text += \" \" + word\n",
    "\n",
    "            return in_text.replace('startseq', '').replace('endseq', '').strip()\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors de la génération de la description: {str(e)}\")\n",
    "            return \"Impossible de générer une description\"\n",
    "\n",
    "    def analyze_image(self):\n",
    "        \"\"\"Analyse une image sélectionnée\"\"\"\n",
    "        self.status_var.set(\"Analyse de l'image...\")\n",
    "        # Ouvrir le sélecteur de fichier\n",
    "        file_path = filedialog.askopenfilename(\n",
    "            title=\"Sélectionner une image\",\n",
    "            filetypes=[(\"Images\", \"*.jpg *.jpeg *.png *.bmp\")]\n",
    "        )\n",
    "\n",
    "        if not file_path:\n",
    "            return\n",
    "\n",
    "\n",
    "        # Vérifier que les modèles sont chargés\n",
    "        if not self.load_models() or not self.load_caption_models():\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            # Lire l'image\n",
    "            frame = cv2.imread(file_path)\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # Convertir en RGB pour DeepFace\n",
    "\n",
    "            # Générer la description de l'image\n",
    "            description = self.generate_image_caption(frame)\n",
    "\n",
    "            # Détection d'objets\n",
    "            detections = self.detect_objects(frame)\n",
    "            self.status_var.set(\"Analyse de l'image...\")\n",
    "            for detection in detections:\n",
    "                # Extraire les coordonnées et dessiner un rectangle rouge\n",
    "                x1, y1, x2, y2 = detection['coords']\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)  # Rouge\n",
    "\n",
    "                # Ajouter le texte de l'objet interdit en rouge\n",
    "                text = f\"{detection['objet']}\"\n",
    "                cv2.putText(frame, text, (x1, y1 - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "            # Reconnaissance faciale\n",
    "            face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades +\n",
    "                                               'haarcascade_frontalface_default.xml')\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "            faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "            for (x, y, w, h) in faces:\n",
    "                margin = 20\n",
    "                y1 = max(0, y - margin)\n",
    "                y2 = min(frame.shape[0], y + h + margin)\n",
    "                x1 = max(0, x - margin)\n",
    "                x2 = min(frame.shape[1], x + w + margin)\n",
    "                face_img = frame[y1:y2, x1:x2]\n",
    "\n",
    "                try:\n",
    "                    embedding = DeepFace.represent(face_img, model_name=\"ArcFace\",\n",
    "                                                 enforce_detection=False)\n",
    "\n",
    "                    if embedding:\n",
    "                        embedding_array = np.array([embedding[0][\"embedding\"]])\n",
    "                        prediction = self.face_model.predict(embedding_array, verbose=0)\n",
    "                        predicted_class = np.argmax(prediction)\n",
    "                        confidence = prediction[0][predicted_class]\n",
    "\n",
    "                        predicted_name = self.label_map[predicted_class]\n",
    "                        if confidence < 0.75:  # Seuil de confiance\n",
    "                            predicted_name = \"Inconnu\"\n",
    "                            color = (255, 0, 0)  # Rouge pour inconnu\n",
    "                            text = predicted_name\n",
    "                        else:\n",
    "                            predicted_name = self.label_map[predicted_class]\n",
    "                            color = (0, int(255 * confidence), 0)\n",
    "                            text = f\"{predicted_name} ({confidence:.2f})\"\n",
    "\n",
    "                        cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "                        cv2.putText(frame, text, (x, y-10),\n",
    "                                  cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "                except Exception as e:\n",
    "                    cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "            # Afficher la description sur l'image\n",
    "            desc_lines = textwrap.wrap(description, width=40)\n",
    "            y_pos = 30\n",
    "            for line in desc_lines:\n",
    "                # Obtenir la taille du texte pour créer le rectangle de fond\n",
    "                (text_width, text_height), _ = cv2.getTextSize(\n",
    "                    line, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 1)\n",
    "\n",
    "                # Dessiner un rectangle blanc comme fond\n",
    "                cv2.rectangle(frame,\n",
    "                            (5, y_pos - text_height - 5),  # Point supérieur gauche\n",
    "                            (15 + text_width, y_pos + 5),   # Point inférieur droit\n",
    "                            (255, 255, 255),                # Couleur du fond (blanc)\n",
    "                            -1)                             # -1 pour remplir le rectangle\n",
    "\n",
    "                # Dessiner le texte noir avec épaisseur normale\n",
    "                cv2.putText(frame, line, (10, y_pos),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 1)\n",
    "\n",
    "                y_pos += 25\n",
    "\n",
    "            self.status_var.set(\"Analyse terminée.\")\n",
    "\n",
    "            # Afficher l'image analysée\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)  # Reconvertir en BGR pour l'affichage\n",
    "            cv2.imshow('Analyse de l\\'image', frame)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Erreur\", f\"Erreur pendant l'analyse de l'image: {str(e)}\")\n",
    "            self.status_var.set(\"Erreur pendant l'analyse\")\n",
    "\n",
    "    def toggle_recognition(self):\n",
    "        \"\"\"Démarre ou arrête la reconnaissance\"\"\"\n",
    "        if not self.is_recognition_running:\n",
    "            if not os.path.exists(\"face_recognition_model.h5\"):\n",
    "                messagebox.showerror(\"Erreur\", \"Le modèle facial n'a pas été entraîné!\")\n",
    "                return\n",
    "\n",
    "            # Charger le modèle facial s'il n'est pas déjà chargé\n",
    "            if not hasattr(self, 'face_model'):\n",
    "                try:\n",
    "                    self.status_var.set(\"Chargement du modèle facial...\")\n",
    "                    self.face_model = load_model(\"face_recognition_model.h5\", compile=False)\n",
    "                    with open(\"label_map.pkl\", 'rb') as f:\n",
    "                        self.label_map = pickle.load(f)\n",
    "                    self.status_var.set(\"Modèle facial chargé\")\n",
    "                except Exception as e:\n",
    "                    messagebox.showerror(\"Erreur\", f\"Erreur lors du chargement du modèle facial: {str(e)}\")\n",
    "                    return\n",
    "\n",
    "            if self.model_yolo is None:\n",
    "                messagebox.showwarning(\"Attention\",\n",
    "                                       \"Le modèle YOLO n'est pas chargé. \" +\n",
    "                                       \"Seule la reconnaissance faciale sera active.\")\n",
    "\n",
    "            self.is_recognition_running = True\n",
    "            self.status_var.set(\"Reconnaissance en cours...\")\n",
    "            threading.Thread(target=self.start_recognition, daemon=True).start()\n",
    "        else:\n",
    "            self.is_recognition_running = False\n",
    "            self.status_var.set(\"Reconnaissance arrêtée\")\n",
    "\n",
    "    def train_model(self):\n",
    "        \"\"\"Fonction d'entraînement du modèle\"\"\"\n",
    "        try:\n",
    "            self.status_var.set(\"Chargement des données...\")\n",
    "            db_path = \"dataset\"\n",
    "            embeddings = []\n",
    "            labels = []\n",
    "            label_map = {}\n",
    "\n",
    "            # Liste tous les dossiers de personnes\n",
    "            all_persons = sorted([d for d in os.listdir(db_path)\n",
    "                                if os.path.isdir(os.path.join(db_path, d))])\n",
    "            total_persons = len(all_persons)\n",
    "\n",
    "            for idx, person in enumerate(all_persons):\n",
    "                person_path = os.path.join(db_path, person)\n",
    "                label_map[idx] = person\n",
    "\n",
    "                person_progress = (idx / total_persons) * 50  # Première moitié de la progress bar\n",
    "                self.progress_var.set(person_progress)\n",
    "                self.status_var.set(f\"Traitement des images de {person}...\")\n",
    "\n",
    "                for image_name in os.listdir(person_path):\n",
    "                    image_path = os.path.join(person_path, image_name)\n",
    "                    try:\n",
    "                        embedding = DeepFace.represent(image_path, model_name=\"ArcFace\",\n",
    "                                                     enforce_detection=False)\n",
    "                        embeddings.append(embedding[0][\"embedding\"])\n",
    "                        labels.append(idx)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Erreur avec {image_path}: {e}\")\n",
    "\n",
    "            embeddings = np.array(embeddings)\n",
    "            labels = np.array(labels)\n",
    "\n",
    "            # Préparation des données\n",
    "            self.status_var.set(\"Préparation des données...\")\n",
    "            X_train, X_test, y_train, y_test = train_test_split(embeddings, labels,\n",
    "                                                               test_size=0.2, random_state=42)\n",
    "            y_train = to_categorical(y_train, num_classes=len(label_map))\n",
    "            y_test = to_categorical(y_test, num_classes=len(label_map))\n",
    "\n",
    "            # Création et compilation du modèle\n",
    "            self.status_var.set(\"Création du modèle...\")\n",
    "            model = Sequential([\n",
    "                Dense(128, input_shape=(embeddings.shape[1],), activation='relu'),\n",
    "                Dropout(0.5),\n",
    "                Dense(64, activation='relu'),\n",
    "                Dropout(0.5),\n",
    "                Dense(len(label_map), activation='softmax')\n",
    "            ])\n",
    "\n",
    "            model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "            # Entraînement\n",
    "            self.status_var.set(\"Entraînement en cours...\")\n",
    "            epochs = 100\n",
    "            for epoch in range(epochs):\n",
    "                model.fit(X_train, y_train, epochs=1, batch_size=16,\n",
    "                         validation_data=(X_test, y_test), verbose=0)\n",
    "                progress = 50 + (epoch / epochs) * 50  # Deuxième moitié de la progress bar\n",
    "                self.progress_var.set(progress)\n",
    "                self.status_var.set(f\"Entraînement: {epoch+1}/{epochs} epochs\")\n",
    "\n",
    "            # Sauvegarde\n",
    "            model.save(\"face_recognition_model.h5\")\n",
    "            with open(\"label_map.pkl\", 'wb') as f:\n",
    "                pickle.dump(label_map, f)\n",
    "\n",
    "            self.progress_var.set(100)\n",
    "            self.status_var.set(\"Entraînement terminé!\")\n",
    "            messagebox.showinfo(\"Succès\", \"Le modèle a été entraîné avec succès!\")\n",
    "\n",
    "        except Exception as e:\n",
    "            self.status_var.set(\"Erreur pendant l'entraînement\")\n",
    "            messagebox.showerror(\"Erreur\", f\"Erreur pendant l'entraînement: {str(e)}\")\n",
    "        finally:\n",
    "            self.training_in_progress = False\n",
    "            self.progress_var.set(0)\n",
    "\n",
    "    def start_training(self):\n",
    "            \"\"\"Démarre l'entraînement dans un thread séparé\"\"\"\n",
    "            if not self.training_in_progress:\n",
    "                self.training_in_progress = True\n",
    "                threading.Thread(target=self.train_model, daemon=True).start()\n",
    "            else:\n",
    "                messagebox.showwarning(\"En cours\", \"L'entraînement est déjà en cours!\")\n",
    "\n",
    "    def logout(self):\n",
    "        self.root.destroy()  # Ferme la fenêtre actuelle\n",
    "        login = LoginWindow()  # Réinstancie la fenêtre de connexion\n",
    "        login.run()  # Lance la fenêtre de connexion\n",
    "\n",
    "\n",
    "# Nouvelle classe pour la détection d'objets\n",
    "class ObjectDetectionThread(threading.Thread):\n",
    "    def __init__(self, frame_queue, result_queue, model_yolo, objets_surveilles):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.frame_queue = frame_queue\n",
    "        self.result_queue = result_queue\n",
    "        self.model_yolo = model_yolo\n",
    "        self.objets_surveilles = objets_surveilles\n",
    "        self.running = True\n",
    "\n",
    "    def run(self):\n",
    "        while self.running:\n",
    "            try:\n",
    "                # Récupérer la frame la plus récente\n",
    "                frame = None\n",
    "                while not self.frame_queue.empty():\n",
    "                    frame = self.frame_queue.get_nowait()\n",
    "\n",
    "                if frame is None:\n",
    "                    time.sleep(0.01)\n",
    "                    continue\n",
    "\n",
    "                # Détection d'objets\n",
    "                old_stdout = sys.stdout\n",
    "                sys.stdout = open(os.devnull, 'w')\n",
    "                results = self.model_yolo(frame, verbose=False)\n",
    "                sys.stdout = old_stdout\n",
    "\n",
    "                detections = []\n",
    "                for r in results:\n",
    "                    boxes = r.boxes\n",
    "                    for box in boxes:\n",
    "                        cls_id = int(box.cls[0])\n",
    "                        for nom_objet, id_classe in self.objets_surveilles.items():\n",
    "                            if cls_id == id_classe:\n",
    "                                x1, y1, x2, y2 = box.xyxy[0]\n",
    "                                confidence = float(box.conf[0])\n",
    "                                if confidence > 0.4:\n",
    "                                    detections.append({\n",
    "                                        'objet': nom_objet,\n",
    "                                        'confiance': confidence,\n",
    "                                        'coords': (int(x1), int(y1), int(x2), int(y2))\n",
    "                                    })\n",
    "\n",
    "                # Envoyer les résultats\n",
    "                self.result_queue.put(detections)\n",
    "\n",
    "            except queue.Empty:\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(f\"Erreur dans le thread de détection d'objets: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "    def stop(self):\n",
    "        self.running = False\n",
    "\n",
    "\n",
    "class FaceRecognitionThread(threading.Thread):\n",
    "    def __init__(self, frame_queue, result_queue, face_model, label_map):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.frame_queue = frame_queue\n",
    "        self.result_queue = result_queue\n",
    "        self.face_model = face_model\n",
    "        self.label_map = label_map\n",
    "        self.running = True\n",
    "\n",
    "    def run(self):\n",
    "        while self.running:\n",
    "            try:\n",
    "                # Récupérer la frame la plus récente, ignore les anciennes\n",
    "                face_img = None\n",
    "                while not self.frame_queue.empty():\n",
    "                    face_img = self.frame_queue.get_nowait()\n",
    "\n",
    "                if face_img is None:\n",
    "                    time.sleep(0.01)  # Petite pause si pas de frame\n",
    "                    continue\n",
    "\n",
    "                # Traitement de la reconnaissance faciale\n",
    "                embedding = DeepFace.represent(face_img, model_name=\"ArcFace\",\n",
    "                                               enforce_detection=False)\n",
    "\n",
    "                if embedding:\n",
    "                    embedding_array = np.array([embedding[0][\"embedding\"]])\n",
    "                    prediction = self.face_model.predict(embedding_array, verbose=0)\n",
    "                    predicted_class = np.argmax(prediction)\n",
    "                    confidence = prediction[0][predicted_class]\n",
    "\n",
    "                    # Envoyer le résultat\n",
    "                    predicted_name = self.label_map[predicted_class] if confidence >= 0.75 else \"Inconnu\"\n",
    "                    self.result_queue.put({\n",
    "                        'name': predicted_name,\n",
    "                        'confidence': confidence\n",
    "                    })\n",
    "\n",
    "            except queue.Empty:\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(f\"Erreur dans le thread de reconnaissance: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "    def stop(self):\n",
    "        self.running = False\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    login = LoginWindow()\n",
    "    login.run()"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
