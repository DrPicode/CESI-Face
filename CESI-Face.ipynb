{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "from tabnanny import verbose\n",
    "\n",
    "def rename_files_and_folders(root_path):\n",
    "    for dirpath, dirnames, filenames in os.walk(root_path):\n",
    "        # Renommer les dossiers\n",
    "        for dirname in dirnames:\n",
    "            new_dirname = dirname.encode(\"ascii\", \"ignore\").decode(\"ascii\").replace(\" \", \"_\")\n",
    "            os.rename(os.path.join(dirpath, dirname), os.path.join(dirpath, new_dirname))\n",
    "\n",
    "        # Renommer les fichiers\n",
    "        for filename in filenames:\n",
    "            new_filename = filename.encode(\"ascii\", \"ignore\").decode(\"ascii\").replace(\" \", \"_\")\n",
    "            os.rename(os.path.join(dirpath, filename), os.path.join(dirpath, new_filename))\n",
    "\n",
    "dataset_path = \"dataset(test)\"\n",
    "rename_files_and_folders(dataset_path)\n",
    "print(\"Renommage terminé.\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T09:18:43.803949Z",
     "start_time": "2025-01-15T09:17:54.907199Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk, messagebox, filedialog\n",
    "from deepface import DeepFace\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications import DenseNet201\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import threading\n",
    "from datetime import datetime\n",
    "from ultralytics import YOLO\n",
    "import logging\n",
    "import sys\n",
    "import json\n",
    "import hashlib\n",
    "import textwrap\n",
    "\n",
    "\n",
    "class LoginWindow:\n",
    "    def __init__(self):\n",
    "        self.root = tk.Tk()\n",
    "        self.root.title(\"Connexion\")\n",
    "        self.root.geometry(\"300x200\")  # Augmenté la hauteur pour le nouveau menu\n",
    "\n",
    "        # Variables\n",
    "        self.password_var = tk.StringVar()\n",
    "        self.action_var = tk.StringVar(value=\"Entrée\")\n",
    "        self.salle_var = tk.StringVar(value=\"100\")  # Valeur par défaut pour la salle\n",
    "\n",
    "        self.create_widgets()\n",
    "\n",
    "    def create_widgets(self):\n",
    "        main_frame = ttk.Frame(self.root, padding=\"20\")\n",
    "        main_frame.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))\n",
    "\n",
    "        # Password field\n",
    "        ttk.Label(main_frame, text=\"Mot de passe:\").grid(row=0, column=0, pady=10)\n",
    "        password_entry = ttk.Entry(main_frame, textvariable=self.password_var, show=\"*\")\n",
    "        password_entry.grid(row=0, column=1, pady=10)\n",
    "\n",
    "        # Action choice (Entrée/Sortie)\n",
    "        ttk.Label(main_frame, text=\"Action:\").grid(row=1, column=0, pady=10)\n",
    "        action_frame = ttk.Frame(main_frame)\n",
    "        action_frame.grid(row=1, column=1, pady=10)\n",
    "\n",
    "        ttk.Radiobutton(action_frame, text=\"Entrée\", variable=self.action_var,\n",
    "                       value=\"Entrée\").pack(side=tk.LEFT, padx=5)\n",
    "        ttk.Radiobutton(action_frame, text=\"Sortie\", variable=self.action_var,\n",
    "                       value=\"Sortie\").pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        # Salle selection\n",
    "        ttk.Label(main_frame, text=\"Numéro de salle:\").grid(row=2, column=0, pady=10)\n",
    "        salles = [str(num) for num in range(100, 111)]  # Crée une liste de \"100\" à \"110\"\n",
    "        salle_combobox = ttk.Combobox(main_frame, textvariable=self.salle_var,\n",
    "                                     values=salles, state=\"readonly\", width=17)\n",
    "        salle_combobox.grid(row=2, column=1, pady=10)\n",
    "\n",
    "        # Login button\n",
    "        ttk.Button(main_frame, text=\"Connexion\",\n",
    "                  command=self.verify_password).grid(row=3, column=0,\n",
    "                                                   columnspan=2, pady=20)\n",
    "\n",
    "        # Center the frame\n",
    "        self.root.grid_rowconfigure(0, weight=1)\n",
    "        self.root.grid_columnconfigure(0, weight=1)\n",
    "\n",
    "    def verify_password(self):\n",
    "        entered_password = self.password_var.get()\n",
    "        action = self.action_var.get()\n",
    "        salle = self.salle_var.get()\n",
    "\n",
    "        # Hash the entered password\n",
    "        hashed_password = hashlib.sha256(entered_password.encode()).hexdigest()\n",
    "\n",
    "        try:\n",
    "            # Load the stored password\n",
    "            with open(\"password_config.json\", \"r\") as f:\n",
    "                config = json.load(f)\n",
    "                stored_password = config.get(\"password\")\n",
    "\n",
    "            if hashed_password == stored_password:\n",
    "                self.root.destroy()  # Close login window\n",
    "                # Start main application\n",
    "                root = tk.Tk()\n",
    "                app = FaceObjectRecognitionApp(root, action, salle)\n",
    "                root.mainloop()\n",
    "            else:\n",
    "                messagebox.showerror(\"Erreur\", \"Mot de passe incorrect\")\n",
    "                self.password_var.set(\"\")  # Clear password field\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            messagebox.showerror(\"Erreur\", \"Fichier de configuration non trouvé\")\n",
    "\n",
    "    def run(self):\n",
    "        self.root.mainloop()\n",
    "\n",
    "class FaceObjectRecognitionApp:\n",
    "    def __init__(self, root, action=\"Entrée\", salle=\"100\"):\n",
    "        self.root = root\n",
    "        self.action = action  # Stocke l'action (Entrée/Sortie)\n",
    "        self.salle = salle    # Stocke le numéro de salle\n",
    "        self.root.title(f\"Système de Reconnaissance - {action} - Salle {salle}\")\n",
    "        self.root.geometry(\"400x200\")\n",
    "\n",
    "        # Variables\n",
    "        self.is_recognition_running = False\n",
    "        self.training_in_progress = False\n",
    "        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "        self.caption_model = None\n",
    "        self.feature_extractor = None\n",
    "        self.tokenizer = None\n",
    "        self.max_length = None\n",
    "\n",
    "        # Objets surveillés\n",
    "        self.OBJETS_SURVEILLES = {\n",
    "            'Sunglasses': 505,\n",
    "            'Hat': 243,\n",
    "            'Shorts': 456,\n",
    "            'Skirt': 463,\n",
    "            'Miniskirt': 334,\n",
    "            'Helmet': 248,\n",
    "            'Kitchen Knife': 292,\n",
    "            'Shotgun': 457,\n",
    "            'Handgun': 238\n",
    "        }\n",
    "\n",
    "        # Style\n",
    "        style = ttk.Style()\n",
    "        style.configure('Big.TButton', padding=10, font=('Helvetica', 12))\n",
    "\n",
    "        # Chargement automatique du modèle YOLO\n",
    "        self.status_var = tk.StringVar(value=\"Chargement du modèle YOLO...\")\n",
    "        self.model_yolo = None\n",
    "        threading.Thread(target=self.load_yolo_model_startup, daemon=True).start()\n",
    "\n",
    "        # Création de l'interface\n",
    "        self.create_widgets()\n",
    "        self.last_logged_person = None  # Pour tracker la dernière personne enregistrée\n",
    "        self.csv_file = \"face_detection_logs.csv\"\n",
    "\n",
    "    def load_yolo_model_startup(self):\n",
    "        \"\"\"Charge le modèle YOLO au démarrage\"\"\"\n",
    "        try:\n",
    "            logging.getLogger(\"ultralytics\").setLevel(logging.WARNING)\n",
    "            self.model_yolo = YOLO(\"yolov8n-oiv7.pt\", verbose=False)\n",
    "            self.status_var.set(\"Modèle YOLO chargé\")\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Erreur\", f\"Erreur lors du chargement de YOLO: {str(e)}\")\n",
    "            self.status_var.set(\"Erreur chargement YOLO\")\n",
    "\n",
    "    def create_widgets(self):\n",
    "        # Ajustement de la taille de la fenêtre\n",
    "        self.root.geometry(\"650x500\")  # Largeur augmentée pour plus d'espace\n",
    "\n",
    "        # Cadre principal avec des marges\n",
    "        main_frame = ttk.Frame(self.root, padding=\"30 20 30 20\")\n",
    "        main_frame.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))\n",
    "\n",
    "        # Configuration de la grille pour un meilleur positionnement\n",
    "        main_frame.columnconfigure(0, weight=1)\n",
    "        main_frame.rowconfigure(0, weight=1)\n",
    "\n",
    "        # Titre avec un style amélioré\n",
    "        title_label = ttk.Label(main_frame,\n",
    "                                text=\"Système de Reconnaissance Faciale et d'Objets\",\n",
    "                                font=('Helvetica', 18, 'bold'),\n",
    "                                wraplength=600,\n",
    "                                anchor='center',\n",
    "                                justify='center')\n",
    "        title_label.grid(row=0, column=0, pady=(0, 20), sticky=tk.N)\n",
    "\n",
    "        # Boutons centrés avec un espacement cohérent\n",
    "        button_frame = ttk.Frame(main_frame)\n",
    "        button_frame.grid(row=1, column=0, pady=(10, 20), sticky=tk.N)\n",
    "\n",
    "        # Liste des boutons et leurs commandes\n",
    "        buttons = [\n",
    "            (\"Enregistrer visage\", self.show_register_dialog),\n",
    "            (\"Entraîner le modèle facial\", self.start_training),\n",
    "            (\"Lancer la reconnaissance\", self.toggle_recognition),\n",
    "            (\"Analyser une image\", self.analyze_image),\n",
    "            (\"Se déconnecter\", self.logout)\n",
    "        ]\n",
    "\n",
    "        # Création dynamique des boutons\n",
    "        for i, (text, command) in enumerate(buttons):\n",
    "            btn = ttk.Button(button_frame, text=text, command=command, style='Big.TButton')\n",
    "            btn.grid(row=i, column=0, pady=10, padx=10, sticky=tk.EW)\n",
    "\n",
    "        # Progress bar avec des marges\n",
    "        self.progress_var = tk.DoubleVar()\n",
    "        self.progress = ttk.Progressbar(main_frame, variable=self.progress_var,\n",
    "                                        maximum=100, mode='determinate')\n",
    "        self.progress.grid(row=2, column=0, pady=(20, 10), sticky=tk.EW)\n",
    "\n",
    "        # Statut avec une apparence plus lisible\n",
    "        status_label = ttk.Label(main_frame, textvariable=self.status_var,\n",
    "                                 wraplength=600, anchor='center', justify='center',\n",
    "                                 font=('Helvetica', 12))\n",
    "        status_label.grid(row=3, column=0, pady=(10, 0), sticky=tk.S)\n",
    "\n",
    "        # Ajout d'un padding global\n",
    "        for child in main_frame.winfo_children():\n",
    "            child.grid_configure(padx=10, pady=5)\n",
    "\n",
    "\n",
    "    def show_register_dialog(self):\n",
    "        \"\"\"Affiche une fenêtre de dialogue pour enregistrer un visage\"\"\"\n",
    "        dialog = tk.Toplevel(self.root)\n",
    "        dialog.title(\"Enregistrer un visage\")\n",
    "        dialog.geometry(\"200x150\")\n",
    "\n",
    "        ttk.Label(dialog, text=\"Prénom:\").grid(row=0, column=0, padx=5, pady=5)\n",
    "        prenom_var = tk.StringVar()\n",
    "        ttk.Entry(dialog, textvariable=prenom_var).grid(row=0, column=1, padx=5, pady=5)\n",
    "\n",
    "        ttk.Label(dialog, text=\"Nom:\").grid(row=1, column=0, padx=5, pady=5)\n",
    "        nom_var = tk.StringVar()\n",
    "        ttk.Entry(dialog, textvariable=nom_var).grid(row=1, column=1, padx=5, pady=5)\n",
    "\n",
    "        def validate():\n",
    "            prenom = prenom_var.get().strip()\n",
    "            nom = nom_var.get().strip()\n",
    "            if prenom and nom:\n",
    "                dialog.destroy()\n",
    "                self.capture_face(prenom, nom)\n",
    "            else:\n",
    "                messagebox.showerror(\"Erreur\", \"Veuillez remplir tous les champs\")\n",
    "\n",
    "        ttk.Button(dialog, text=\"Commencer la capture\",\n",
    "                  command=validate).grid(row=2, column=0, columnspan=2, pady=20)\n",
    "\n",
    "    def capture_face(self, prenom, nom):\n",
    "        \"\"\"Capture les images du visage pour l'enregistrement\"\"\"\n",
    "        # Créer le dossier pour enregistrer les images\n",
    "        folder_name = f\"dataset(test)/{prenom.capitalize()} {nom.capitalize()}\"\n",
    "        if not os.path.exists(folder_name):\n",
    "            os.makedirs(folder_name)\n",
    "\n",
    "        # Ouvrir la caméra\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        captured_images = 0\n",
    "        directions = [\"Regardez en face\", \"Regardez en haut\", \"Regardez vers la droite\",\n",
    "                     \"Regardez en bas\", \"Regardez vers la gauche\"]\n",
    "        images_per_direction = 1\n",
    "        total_images = len(directions) * images_per_direction\n",
    "\n",
    "        direction_index = 0\n",
    "\n",
    "        while captured_images < total_images:\n",
    "            current_direction = directions[direction_index]\n",
    "\n",
    "            # Pause de 3 secondes avec affichage\n",
    "            for i in range(3, 0, -1):\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                cv2.putText(frame, f\"{current_direction} dans {i} secondes\",\n",
    "                           (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "                cv2.imshow('Capturer le visage', frame)\n",
    "                cv2.waitKey(1000)\n",
    "\n",
    "            while captured_images < (direction_index + 1) * images_per_direction:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                faces = self.face_cascade.detectMultiScale(gray, scaleFactor=1.1,\n",
    "                                                         minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "                for (x, y, w, h) in faces:\n",
    "                    # Élargir la zone pour la tête\n",
    "                    x_head = max(0, x - int(0.2 * w))\n",
    "                    y_head = max(0, y - int(0.3 * h))\n",
    "                    w_head = min(frame.shape[1] - x_head, int(w * 1.4))\n",
    "                    h_head = min(frame.shape[0] - y_head, int(h * 1.6))\n",
    "\n",
    "                    head = frame[y_head:y_head+h_head, x_head:x_head+w_head]\n",
    "                    head_filename = f\"{folder_name}/head_{captured_images}.jpg\"\n",
    "                    cv2.imwrite(head_filename, head)\n",
    "                    captured_images += 1\n",
    "\n",
    "                    cv2.putText(frame, f\"Image {captured_images}/{total_images}\",\n",
    "                              (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                    cv2.rectangle(frame, (x_head, y_head),\n",
    "                                (x_head+w_head, y_head+h_head), (0, 255, 0), 2)\n",
    "\n",
    "                cv2.putText(frame, f\"Etape actuelle : {current_direction}\",\n",
    "                          (10, frame.shape[0] - 20),\n",
    "                          cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)\n",
    "\n",
    "                cv2.imshow('Capturer le visage', frame)\n",
    "\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    cap.release()\n",
    "                    cv2.destroyAllWindows()\n",
    "                    return\n",
    "\n",
    "            direction_index = (direction_index + 1) % len(directions)\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        messagebox.showinfo(\"Succès\",\n",
    "                          \"Enregistrement du visage terminé. Veuillez entraîner le modèle.\")\n",
    "\n",
    "    def load_models(self):\n",
    "        \"\"\"Charge les modèles nécessaires\"\"\"\n",
    "        try:\n",
    "            self.status_var.set(\"Chargement du modèle facial...\")\n",
    "            self.face_model = load_model(\"face_recognition_model.h5\", compile=False)\n",
    "            with open(\"label_map.pkl\", 'rb') as f:\n",
    "                self.label_map = pickle.load(f)\n",
    "            self.status_var.set(\"Modèle facial chargé\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Erreur\", f\"Erreur lors du chargement du modèle facial: {str(e)}\")\n",
    "            self.status_var.set(\"Erreur chargement modèle facial\")\n",
    "            return False\n",
    "\n",
    "    def load_caption_models(self):\n",
    "        \"\"\"Charge les modèles nécessaires pour le captioning\"\"\"\n",
    "        try:\n",
    "            self.caption_model = keras.models.load_model('caption_model.keras', safe_mode=False)\n",
    "\n",
    "            # Chargement du tokenizer et max_length\n",
    "            with open('tokenizer.pkl', 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "                self.tokenizer = data['tokenizer']\n",
    "                self.max_length = data['max_length']\n",
    "\n",
    "            # Configuration du modèle DenseNet\n",
    "            model_densenet = DenseNet201()\n",
    "            self.feature_extractor = tf.keras.Model(\n",
    "                inputs=model_densenet.input,\n",
    "                outputs=model_densenet.layers[-2].output\n",
    "            )\n",
    "\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors du chargement des modèles de captioning: {str(e)}\")\n",
    "            messagebox.showerror(\"Erreur\", f\"Erreur lors du chargement des modèles de captioning: {str(e)}\")\n",
    "            return False\n",
    "\n",
    "    def detect_objects(self, frame):\n",
    "        \"\"\"Détecte les objets dans la frame\"\"\"\n",
    "        if self.model_yolo is None:\n",
    "            return []\n",
    "\n",
    "        old_stdout = sys.stdout\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "        results = self.model_yolo(frame, verbose=False)\n",
    "\n",
    "        sys.stdout = old_stdout\n",
    "\n",
    "        detections = []\n",
    "\n",
    "        for r in results:\n",
    "            boxes = r.boxes\n",
    "            for box in boxes:\n",
    "                cls_id = int(box.cls[0])\n",
    "                for nom_objet, id_classe in self.OBJETS_SURVEILLES.items():\n",
    "                    if cls_id == id_classe:\n",
    "                        x1, y1, x2, y2 = box.xyxy[0]\n",
    "                        confidence = float(box.conf[0])\n",
    "                        if confidence > 0.4:\n",
    "                            detections.append({\n",
    "                                'objet': nom_objet,\n",
    "                                'confiance': confidence,\n",
    "                                'coords': (int(x1), int(y1), int(x2), int(y2))\n",
    "                            })\n",
    "        return detections\n",
    "\n",
    "    def log_detection(self, personne, objets_interdits):\n",
    "        \"\"\"\n",
    "        Enregistre une détection dans le fichier CSV si ce n'est pas un doublon consécutif\n",
    "        \"\"\"\n",
    "        if personne == \"Inconnu\" or personne == self.last_logged_person:\n",
    "            return False\n",
    "\n",
    "        current_time = datetime.now()\n",
    "        date = current_time.strftime('%d/%m/%Y')\n",
    "        heure = current_time.strftime('%H:%M:%S')\n",
    "\n",
    "        objets_str = \"|\".join(objets_interdits) if objets_interdits else \"Aucun\"\n",
    "\n",
    "        with open(self.csv_file, 'a', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f, delimiter=';')\n",
    "            writer.writerow([date, heure, personne, objets_str, self.action, self.salle])\n",
    "\n",
    "        self.last_logged_person = personne\n",
    "        return True\n",
    "\n",
    "    def start_recognition(self):\n",
    "        \"\"\"Fonction de reconnaissance en temps réel avec logging\"\"\"\n",
    "        try:\n",
    "            # Charger le modèle de reconnaissance faciale\n",
    "            model = load_model(\"face_recognition_model.h5\", compile=False)\n",
    "            with open(\"label_map.pkl\", 'rb') as f:\n",
    "                label_map = pickle.load(f)\n",
    "\n",
    "            cap = cv2.VideoCapture(0)\n",
    "            face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "            last_predictions = []\n",
    "            PREDICTION_MEMORY = 5\n",
    "\n",
    "            while self.is_recognition_running:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "\n",
    "                # Détection d'objets\n",
    "                detections = self.detect_objects(frame)\n",
    "                objets_interdits = []\n",
    "\n",
    "                for detection in detections:\n",
    "                    # Vérifier si l'objet est surveillé\n",
    "                    if detection['objet'] in self.OBJETS_SURVEILLES:\n",
    "                        objets_interdits.append(detection['objet'])\n",
    "                        # Extraire les coordonnées et dessiner un rectangle rouge\n",
    "                        x1, y1, x2, y2 = detection['coords']\n",
    "                        cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)  # Rouge\n",
    "\n",
    "                        # Ajouter le texte de l'objet interdit en rouge\n",
    "                        text = f\"{detection['objet']} ({detection['confiance']:.2f})\"\n",
    "                        cv2.putText(frame, text, (x1, y1 - 10),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "                # Reconnaissance faciale\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "                for (x, y, w, h) in faces:\n",
    "                    margin = 20\n",
    "                    y1 = max(0, y - margin)\n",
    "                    y2 = min(frame.shape[0], y + h + margin)\n",
    "                    x1 = max(0, x - margin)\n",
    "                    x2 = min(frame.shape[1], x + w + margin)\n",
    "                    face_img = frame[y1:y2, x1:x2]\n",
    "\n",
    "                    try:\n",
    "                        embedding = DeepFace.represent(face_img, model_name=\"ArcFace\",\n",
    "                                                     enforce_detection=False)\n",
    "\n",
    "                        if embedding:\n",
    "                            embedding_array = np.array([embedding[0][\"embedding\"]])\n",
    "                            prediction = model.predict(embedding_array, verbose=0)\n",
    "                            predicted_class = np.argmax(prediction)\n",
    "                            confidence = prediction[0][predicted_class]\n",
    "\n",
    "                            # Système de lissage\n",
    "                            last_predictions.append((predicted_class, confidence))\n",
    "                            if len(last_predictions) > PREDICTION_MEMORY:\n",
    "                                last_predictions.pop(0)\n",
    "\n",
    "                            if len(last_predictions) >= 3:\n",
    "                                class_counts = {}\n",
    "                                for pred_class, conf in last_predictions:\n",
    "                                    if pred_class not in class_counts:\n",
    "                                        class_counts[pred_class] = []\n",
    "                                    class_counts[pred_class].append(conf)\n",
    "\n",
    "                                most_common_class = max(class_counts.items(),\n",
    "                                                      key=lambda x: (len(x[1]),\n",
    "                                                                   sum(x[1])/len(x[1])))[0]\n",
    "                                avg_confidence = np.mean(class_counts[most_common_class])\n",
    "\n",
    "                                predicted_class = most_common_class\n",
    "                                confidence = avg_confidence\n",
    "\n",
    "                            predicted_name = label_map[predicted_class]\n",
    "                            if confidence < 0.75:  # Seuil de confiance\n",
    "                                predicted_name = \"Inconnu\"\n",
    "                                color = (0, 0, 255)  # Rouge pour inconnu\n",
    "                                text = predicted_name\n",
    "                            else:\n",
    "                                predicted_name = label_map[predicted_class]\n",
    "                                color = (0, int(255 * confidence), 0)\n",
    "                                text = f\"{predicted_name} ({confidence:.2f})\"\n",
    "                                self.log_detection(predicted_name, objets_interdits)\n",
    "\n",
    "                            cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "                            cv2.putText(frame, text, (x, y-10),\n",
    "                                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "                    except Exception as e:\n",
    "                        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "\n",
    "                cv2.imshow('Système de reconnaissance', frame)\n",
    "\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Erreur\", f\"Erreur pendant la reconnaissance: {str(e)}\")\n",
    "            self.status_var.set(\"Erreur pendant la reconnaissance\")\n",
    "        finally:\n",
    "            self.is_recognition_running = False\n",
    "\n",
    "    def generate_image_caption(self, image):\n",
    "        \"\"\"Génère une description de l'image\"\"\"\n",
    "        try:\n",
    "            # Redimensionner l'image pour DenseNet\n",
    "            img_array = cv2.resize(image, (224, 224))\n",
    "            if len(img_array.shape) == 2:  # Si l'image est en niveaux de gris\n",
    "                img_array = cv2.cvtColor(img_array, cv2.COLOR_GRAY2RGB)\n",
    "            elif img_array.shape[2] == 4:  # Si l'image a un canal alpha\n",
    "                img_array = cv2.cvtColor(img_array, cv2.COLOR_BGRA2RGB)\n",
    "\n",
    "            img_array = img_array / 255.\n",
    "            img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "            # Extraire les caractéristiques\n",
    "            feature = self.feature_extractor.predict(img_array, verbose=0)\n",
    "\n",
    "            # Générer la description\n",
    "            in_text = \"startseq\"\n",
    "            for i in range(self.max_length):\n",
    "                sequence = self.tokenizer.texts_to_sequences([in_text])[0]\n",
    "                sequence = pad_sequences([sequence], maxlen=self.max_length)\n",
    "\n",
    "                y_pred = self.caption_model.predict([feature, sequence], verbose=0)\n",
    "                y_pred = np.argmax(y_pred)\n",
    "\n",
    "                word = next((word for word, index in self.tokenizer.word_index.items()\n",
    "                           if index == y_pred), None)\n",
    "\n",
    "                if word is None or word == 'endseq':\n",
    "                    break\n",
    "\n",
    "                in_text += \" \" + word\n",
    "\n",
    "            return in_text.replace('startseq', '').replace('endseq', '').strip()\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors de la génération de la description: {str(e)}\")\n",
    "            return \"Impossible de générer une description\"\n",
    "\n",
    "    def analyze_image(self):\n",
    "        \"\"\"Analyse une image sélectionnée\"\"\"\n",
    "        # Ouvrir le sélecteur de fichier\n",
    "        file_path = filedialog.askopenfilename(\n",
    "            title=\"Sélectionner une image\",\n",
    "            filetypes=[(\"Images\", \"*.jpg *.jpeg *.png *.bmp\")]\n",
    "        )\n",
    "\n",
    "        if not file_path:\n",
    "            return\n",
    "\n",
    "        # Vérifier que les modèles sont chargés\n",
    "        if not self.load_models() or not self.load_caption_models():\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            # Lire l'image\n",
    "            frame = cv2.imread(file_path)\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # Convertir en RGB pour DeepFace\n",
    "\n",
    "            # Générer la description de l'image\n",
    "            description = self.generate_image_caption(frame)\n",
    "\n",
    "            # Détection d'objets\n",
    "            detections = self.detect_objects(frame)\n",
    "            for detection in detections:\n",
    "                # Extraire les coordonnées et dessiner un rectangle rouge\n",
    "                x1, y1, x2, y2 = detection['coords']\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)  # Rouge\n",
    "\n",
    "                # Ajouter le texte de l'objet interdit en rouge\n",
    "                text = f\"{detection['objet']} ({detection['confiance']:.2f})\"\n",
    "                cv2.putText(frame, text, (x1, y1 - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "            # Reconnaissance faciale\n",
    "            face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades +\n",
    "                                               'haarcascade_frontalface_default.xml')\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "            faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "            for (x, y, w, h) in faces:\n",
    "                margin = 20\n",
    "                y1 = max(0, y - margin)\n",
    "                y2 = min(frame.shape[0], y + h + margin)\n",
    "                x1 = max(0, x - margin)\n",
    "                x2 = min(frame.shape[1], x + w + margin)\n",
    "                face_img = frame[y1:y2, x1:x2]\n",
    "\n",
    "                try:\n",
    "                    embedding = DeepFace.represent(face_img, model_name=\"ArcFace\",\n",
    "                                                 enforce_detection=False)\n",
    "\n",
    "                    if embedding:\n",
    "                        embedding_array = np.array([embedding[0][\"embedding\"]])\n",
    "                        prediction = self.face_model.predict(embedding_array, verbose=0)\n",
    "                        predicted_class = np.argmax(prediction)\n",
    "                        confidence = prediction[0][predicted_class]\n",
    "\n",
    "                        predicted_name = self.label_map[predicted_class]\n",
    "                        if confidence < 0.75:  # Seuil de confiance\n",
    "                            predicted_name = \"Inconnu\"\n",
    "                            color = (0, 0, 255)  # Rouge pour inconnu\n",
    "                            text = predicted_name\n",
    "                        else:\n",
    "                            predicted_name = self.label_map[predicted_class]\n",
    "                            color = (0, int(255 * confidence), 0)\n",
    "                            text = f\"{predicted_name} ({confidence:.2f})\"\n",
    "\n",
    "                        cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "                        cv2.putText(frame, text, (x, y-10),\n",
    "                                  cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "                except Exception as e:\n",
    "                    cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "\n",
    "            # Afficher la description sur l'image\n",
    "            desc_lines = textwrap.wrap(description, width=40)\n",
    "            y_pos = 30\n",
    "            for line in desc_lines:\n",
    "                # Obtenir la taille du texte pour créer le rectangle de fond\n",
    "                (text_width, text_height), _ = cv2.getTextSize(\n",
    "                    line, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 1)\n",
    "\n",
    "                # Dessiner un rectangle blanc comme fond\n",
    "                cv2.rectangle(frame,\n",
    "                            (5, y_pos - text_height - 5),  # Point supérieur gauche\n",
    "                            (15 + text_width, y_pos + 5),   # Point inférieur droit\n",
    "                            (255, 255, 255),                # Couleur du fond (blanc)\n",
    "                            -1)                             # -1 pour remplir le rectangle\n",
    "\n",
    "                # Dessiner le texte noir avec épaisseur normale\n",
    "                cv2.putText(frame, line, (10, y_pos),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 1)\n",
    "\n",
    "                y_pos += 25\n",
    "\n",
    "            # Afficher l'image analysée\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)  # Reconvertir en BGR pour l'affichage\n",
    "            cv2.imshow('Analyse de l\\'image', frame)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Erreur\", f\"Erreur pendant l'analyse de l'image: {str(e)}\")\n",
    "            self.status_var.set(\"Erreur pendant l'analyse\")\n",
    "\n",
    "    def toggle_recognition(self):\n",
    "        \"\"\"Démarre ou arrête la reconnaissance\"\"\"\n",
    "        if not self.is_recognition_running:\n",
    "            if not os.path.exists(\"face_recognition_model.h5\"):\n",
    "                messagebox.showerror(\"Erreur\", \"Le modèle facial n'a pas été entraîné!\")\n",
    "                return\n",
    "\n",
    "            if self.model_yolo is None:\n",
    "                messagebox.showwarning(\"Attention\",\n",
    "                                     \"Le modèle YOLO n'est pas chargé. \" +\n",
    "                                     \"Seule la reconnaissance faciale sera active.\")\n",
    "\n",
    "            self.is_recognition_running = True\n",
    "            self.status_var.set(\"Reconnaissance en cours...\")\n",
    "            threading.Thread(target=self.start_recognition, daemon=True).start()\n",
    "        else:\n",
    "            self.is_recognition_running = False\n",
    "            self.status_var.set(\"Reconnaissance arrêtée\")\n",
    "\n",
    "    def train_model(self):\n",
    "        \"\"\"Fonction d'entraînement du modèle\"\"\"\n",
    "        try:\n",
    "            self.status_var.set(\"Chargement des données...\")\n",
    "            db_path = \"dataset(test)\"\n",
    "            embeddings = []\n",
    "            labels = []\n",
    "            label_map = {}\n",
    "\n",
    "            # Liste tous les dossiers de personnes\n",
    "            all_persons = sorted([d for d in os.listdir(db_path)\n",
    "                                if os.path.isdir(os.path.join(db_path, d))])\n",
    "            total_persons = len(all_persons)\n",
    "\n",
    "            for idx, person in enumerate(all_persons):\n",
    "                person_path = os.path.join(db_path, person)\n",
    "                label_map[idx] = person\n",
    "\n",
    "                person_progress = (idx / total_persons) * 50  # Première moitié de la progress bar\n",
    "                self.progress_var.set(person_progress)\n",
    "                self.status_var.set(f\"Traitement des images de {person}...\")\n",
    "\n",
    "                for image_name in os.listdir(person_path):\n",
    "                    image_path = os.path.join(person_path, image_name)\n",
    "                    try:\n",
    "                        embedding = DeepFace.represent(image_path, model_name=\"ArcFace\",\n",
    "                                                     enforce_detection=False)\n",
    "                        embeddings.append(embedding[0][\"embedding\"])\n",
    "                        labels.append(idx)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Erreur avec {image_path}: {e}\")\n",
    "\n",
    "            embeddings = np.array(embeddings)\n",
    "            labels = np.array(labels)\n",
    "\n",
    "            # Préparation des données\n",
    "            self.status_var.set(\"Préparation des données...\")\n",
    "            X_train, X_test, y_train, y_test = train_test_split(embeddings, labels,\n",
    "                                                               test_size=0.2, random_state=42)\n",
    "            y_train = to_categorical(y_train, num_classes=len(label_map))\n",
    "            y_test = to_categorical(y_test, num_classes=len(label_map))\n",
    "\n",
    "            # Création et compilation du modèle\n",
    "            self.status_var.set(\"Création du modèle...\")\n",
    "            model = Sequential([\n",
    "                Dense(128, input_shape=(embeddings.shape[1],), activation='relu'),\n",
    "                Dropout(0.5),\n",
    "                Dense(64, activation='relu'),\n",
    "                Dropout(0.5),\n",
    "                Dense(len(label_map), activation='softmax')\n",
    "            ])\n",
    "\n",
    "            model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "            # Entraînement\n",
    "            self.status_var.set(\"Entraînement en cours...\")\n",
    "            epochs = 100\n",
    "            for epoch in range(epochs):\n",
    "                model.fit(X_train, y_train, epochs=1, batch_size=16,\n",
    "                         validation_data=(X_test, y_test), verbose=0)\n",
    "                progress = 50 + (epoch / epochs) * 50  # Deuxième moitié de la progress bar\n",
    "                self.progress_var.set(progress)\n",
    "                self.status_var.set(f\"Entraînement: {epoch+1}/{epochs} epochs\")\n",
    "\n",
    "            # Sauvegarde\n",
    "            model.save(\"face_recognition_model.h5\")\n",
    "            with open(\"label_map.pkl\", 'wb') as f:\n",
    "                pickle.dump(label_map, f)\n",
    "\n",
    "            self.progress_var.set(100)\n",
    "            self.status_var.set(\"Entraînement terminé!\")\n",
    "            messagebox.showinfo(\"Succès\", \"Le modèle a été entraîné avec succès!\")\n",
    "\n",
    "        except Exception as e:\n",
    "            self.status_var.set(\"Erreur pendant l'entraînement\")\n",
    "            messagebox.showerror(\"Erreur\", f\"Erreur pendant l'entraînement: {str(e)}\")\n",
    "        finally:\n",
    "            self.training_in_progress = False\n",
    "            self.progress_var.set(0)\n",
    "\n",
    "    def start_training(self):\n",
    "            \"\"\"Démarre l'entraînement dans un thread séparé\"\"\"\n",
    "            if not self.training_in_progress:\n",
    "                self.training_in_progress = True\n",
    "                threading.Thread(target=self.train_model, daemon=True).start()\n",
    "            else:\n",
    "                messagebox.showwarning(\"En cours\", \"L'entraînement est déjà en cours!\")\n",
    "\n",
    "    def logout(self):\n",
    "        self.root.destroy()  # Ferme la fenêtre actuelle\n",
    "        login = LoginWindow()  # Réinstancie la fenêtre de connexion\n",
    "        login.run()  # Lance la fenêtre de connexion\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    login = LoginWindow()\n",
    "    login.run()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\waute\\anaconda3\\Lib\\tkinter\\__init__.py\", line 1968, in __call__\n",
      "    return self.func(*args)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\waute\\AppData\\Local\\Temp\\ipykernel_9988\\1601519558.py\", line 95, in verify_password\n",
      "    root.mainloop()\n",
      "  File \"C:\\Users\\waute\\anaconda3\\Lib\\tkinter\\__init__.py\", line 1505, in mainloop\n",
      "    self.tk.mainloop(n)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
